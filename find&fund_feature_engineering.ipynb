{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tar-ive/find-fund/blob/main/find%26fund_feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJvNaD9AOdy9",
        "outputId": "1e539a44-4cdb-416f-fd48-a70710dc2f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting hopsworks\n",
            "  Downloading hopsworks-4.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyhumps==1.6.1 (from hopsworks)\n",
            "  Downloading pyhumps-1.6.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2.32.3)\n",
            "Collecting furl (from hopsworks)\n",
            "  Downloading furl-2.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting boto3 (from hopsworks)\n",
            "  Downloading boto3-1.35.92-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting pandas<2.2.0 (from hopsworks)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pyjks (from hopsworks)\n",
            "  Downloading pyjks-20.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mock (from hopsworks)\n",
            "  Downloading mock-5.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting avro==1.11.3 (from hopsworks)\n",
            "  Downloading avro-1.11.3.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2.0.36)\n",
            "Collecting PyMySQL[rsa] (from hopsworks)\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from hopsworks) (5.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2024.10.0)\n",
            "Collecting retrying (from hopsworks)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting hopsworks_aiomysql==0.2.1 (from hopsworks_aiomysql[sa]==0.2.1->hopsworks)\n",
            "  Downloading hopsworks_aiomysql-0.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting opensearch-py<=2.4.2,>=1.1.0 (from hopsworks)\n",
            "  Downloading opensearch_py-2.4.2-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hopsworks) (4.67.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (1.68.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.25.4 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (4.25.5)\n",
            "Collecting sqlalchemy (from hopsworks)\n",
            "  Downloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.2.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2024.12.14)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->hopsworks) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->hopsworks) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->hopsworks) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hopsworks) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hopsworks) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->hopsworks) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->hopsworks) (3.1.1)\n",
            "Collecting botocore<1.36.0,>=1.35.92 (from boto3->hopsworks)\n",
            "  Downloading botocore-1.35.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->hopsworks)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->hopsworks)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting orderedmultidict>=1.0.1 (from furl->hopsworks)\n",
            "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting javaobj-py3 (from pyjks->hopsworks)\n",
            "  Downloading javaobj_py3-0.4.4-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyasn1>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (0.4.1)\n",
            "Collecting pycryptodomex (from pyjks->hopsworks)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting twofish (from pyjks->hopsworks)\n",
            "  Downloading twofish-0.3.0.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from PyMySQL[rsa]->hopsworks) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->PyMySQL[rsa]->hopsworks) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->PyMySQL[rsa]->hopsworks) (2.22)\n",
            "Downloading hopsworks-4.1.4-py3-none-any.whl (640 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.3/640.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hopsworks_aiomysql-0.2.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyhumps-1.6.1-py3-none-any.whl (5.0 kB)\n",
            "Downloading opensearch_py-2.4.2-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.6/258.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.92-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading furl-2.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Downloading pyjks-20.0.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading botocore-1.35.92-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading javaobj_py3-0.4.4-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: avro, twofish\n",
            "  Building wheel for avro (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro: filename=avro-1.11.3-py2.py3-none-any.whl size=123910 sha256=f13e5d5a1f24474f0c5b01ee7d5b46c379a1b351b5368f12c1984737037b8419\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/f6/41/0e0399396af07060e64d4e32c8bd259b48b98a4a114df31294\n",
            "  Building wheel for twofish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twofish: filename=twofish-0.3.0-cp310-cp310-linux_x86_64.whl size=24196 sha256=b262ac732beecb1ae62ad77d7ba8e4498d91757ca265e9de0de19cd40ccbb1a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/3c/27/c390be4f3e8a299d4b2836f8daa19697eb991eacbfabe25031\n",
            "Successfully built avro twofish\n",
            "Installing collected packages: twofish, pyhumps, javaobj-py3, sqlalchemy, retrying, PyMySQL, pycryptodomex, orderedmultidict, mock, jmespath, avro, pyjks, pandas, opensearch-py, hopsworks_aiomysql, furl, botocore, s3transfer, boto3, hopsworks\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "plotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMySQL-1.1.1 avro-1.11.3 boto3-1.35.92 botocore-1.35.92 furl-2.1.3 hopsworks-4.1.4 hopsworks_aiomysql-0.2.1 javaobj-py3-0.4.4 jmespath-1.0.1 mock-5.1.0 opensearch-py-2.4.2 orderedmultidict-1.0.1 pandas-2.1.4 pycryptodomex-3.21.0 pyhumps-1.6.1 pyjks-20.0.0 retrying-1.3.4 s3transfer-0.10.4 sqlalchemy-2.0.29 twofish-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install hopsworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taX_Q8FsUyW_"
      },
      "source": [
        "## Collect Texas State University researchers data using OpenAlex API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVd8Wo71PLan"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beYxnIg_435c",
        "outputId": "f8062362-7cf5-49ad-e8b0-80c636d9098c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found Texas State University ID: https://openalex.org/I13511017\n",
            "Fetching top 500 cited researchers from Texas State University...\n",
            "\n",
            "Processing researcher data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [10:22<00:00,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 500 Researchers CSV head:\n",
            "                      researcher_id     researcher_name  total_citations  \\\n",
            "0  https://openalex.org/A5046299069      Larry R. Price            26301   \n",
            "1  https://openalex.org/A5039371296   Michael A. Huston            21477   \n",
            "2  https://openalex.org/A5070163403       Marcus Felson            21278   \n",
            "3  https://openalex.org/A5017593645  Togay Ozbakkaloglu            18853   \n",
            "4  https://openalex.org/A5048215687          Eric Kirby            12428   \n",
            "\n",
            "   total_works  h_index  i10_index          concept_1  concept_1_score  \\\n",
            "0          208       52        108   Computer science             73.1   \n",
            "1           93       43         61            Biology             93.5   \n",
            "2          161       40         70          Sociology             72.7   \n",
            "3          345       75        207  Materials science             95.9   \n",
            "4          278       49         88            Geology             93.2   \n",
            "\n",
            "            concept_2  concept_2_score  ...                     top_work_5_id  \\\n",
            "0         Mathematics             70.7  ...  https://openalex.org/W2025106538   \n",
            "1             Ecology             86.0  ...  https://openalex.org/W2088443113   \n",
            "2          Psychology             65.2  ...  https://openalex.org/W2311383940   \n",
            "3  Composite material             95.1  ...  https://openalex.org/W2330198871   \n",
            "4             Biology             87.8  ...  https://openalex.org/W2145347294   \n",
            "\n",
            "   top_work_5_type  top_work_5_is_oa  \\\n",
            "0          article             False   \n",
            "1          article             False   \n",
            "2          article             False   \n",
            "3           review             False   \n",
            "4          article              True   \n",
            "\n",
            "                                 top_work_5_keywords  \\\n",
            "0  Psychology,Exposure therapy,Virtual reality,Ps...   \n",
            "1  Microsite,Facilitation,Competition (biology),C...   \n",
            "2  Consumption (sociology),Sociology,Computer sci...   \n",
            "3  Materials science,Shrinkage,Flexural strength,...   \n",
            "4  Thermochronology,Geology,Denudation,Fission tr...   \n",
            "\n",
            "                               top_work_5_source  \\\n",
            "0  Journal of Consulting and Clinical Psychology   \n",
            "1                                        Ecology   \n",
            "2                  American Behavioral Scientist   \n",
            "3                   Journal of Materials Science   \n",
            "4                                      Tectonics   \n",
            "\n",
            "                 top_collaborator_1                top_collaborator_2  \\\n",
            "0  https://openalex.org/A5019375929  https://openalex.org/A5009004096   \n",
            "1  https://openalex.org/A5024934767  https://openalex.org/A5110483019   \n",
            "2  https://openalex.org/A5046958460  https://openalex.org/A5102936013   \n",
            "3  https://openalex.org/A5082132566  https://openalex.org/A5043329482   \n",
            "4  https://openalex.org/A5038349665  https://openalex.org/A5090086069   \n",
            "\n",
            "                 top_collaborator_3                top_collaborator_4  \\\n",
            "0  https://openalex.org/A5101870896  https://openalex.org/A5085670077   \n",
            "1  https://openalex.org/A5038398105  https://openalex.org/A5008653559   \n",
            "2  https://openalex.org/A5037722191  https://openalex.org/A5109563801   \n",
            "3  https://openalex.org/A5040407357  https://openalex.org/A5011064916   \n",
            "4  https://openalex.org/A5100685756  https://openalex.org/A5038670501   \n",
            "\n",
            "                 top_collaborator_5  \n",
            "0  https://openalex.org/A5107483970  \n",
            "1  https://openalex.org/A5103521151  \n",
            "2  https://openalex.org/A5072647442  \n",
            "3  https://openalex.org/A5019907987  \n",
            "4  https://openalex.org/A5009378840  \n",
            "\n",
            "[5 rows x 46 columns]\n",
            "\n",
            "Number of researchers: 500\n",
            "Number of columns: 46\n",
            "\n",
            "Column names:\n",
            "['researcher_id', 'researcher_name', 'total_citations', 'total_works', 'h_index', 'i10_index', 'concept_1', 'concept_1_score', 'concept_2', 'concept_2_score', 'years_active', 'recent_works_count', 'recent_citations', 'unique_venues', 'avg_coauthors', 'open_access_ratio', 'top_work_1_id', 'top_work_1_type', 'top_work_1_is_oa', 'top_work_1_keywords', 'top_work_1_source', 'top_work_2_id', 'top_work_2_type', 'top_work_2_is_oa', 'top_work_2_keywords', 'top_work_2_source', 'top_work_3_id', 'top_work_3_type', 'top_work_3_is_oa', 'top_work_3_keywords', 'top_work_3_source', 'top_work_4_id', 'top_work_4_type', 'top_work_4_is_oa', 'top_work_4_keywords', 'top_work_4_source', 'top_work_5_id', 'top_work_5_type', 'top_work_5_is_oa', 'top_work_5_keywords', 'top_work_5_source', 'top_collaborator_1', 'top_collaborator_2', 'top_collaborator_3', 'top_collaborator_4', 'top_collaborator_5']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "def call_openalex_api(endpoint, params=None):\n",
        "    \"\"\"Make API calls with rate limiting and error handling\"\"\"\n",
        "    base_url = f\"https://api.openalex.org/{endpoint}\"\n",
        "    headers = {'User-Agent': 'mailto:your_email@example.com'}  # Replace with your email\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        time.sleep(0.2)  # Rate limiting\n",
        "        return response.json()\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling {endpoint} API: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def get_texas_state_id():\n",
        "    \"\"\"Get Texas State University's OpenAlex ID.\"\"\"\n",
        "    params = {\n",
        "        'filter': 'display_name.search:texas state university',\n",
        "        'per-page': 1\n",
        "    }\n",
        "    response = call_openalex_api('institutions', params)\n",
        "    if response and 'results' in response and response['results']:\n",
        "        return response['results'][0]['id']\n",
        "    return None\n",
        "\n",
        "def fetch_top_cited_researchers(institution_id, max_researchers=500):\n",
        "    \"\"\"Fetch the top cited researchers affiliated with an institution.\"\"\"\n",
        "    all_researchers = []\n",
        "    cursor = '*'  # Initial cursor\n",
        "\n",
        "    while cursor and len(all_researchers) < max_researchers:\n",
        "        try:\n",
        "            params = {\n",
        "                'filter': f'last_known_institutions.id:{institution_id}',\n",
        "                'per-page': 100,  # Max per page\n",
        "                'sort': 'cited_by_count:desc',\n",
        "                'cursor': cursor\n",
        "            }\n",
        "\n",
        "            response = call_openalex_api('authors', params)\n",
        "\n",
        "            if not response or 'results' not in response:\n",
        "                break\n",
        "\n",
        "            researchers = response['results']\n",
        "            if not researchers:\n",
        "                break\n",
        "\n",
        "            # Add researchers to the list\n",
        "            all_researchers.extend(researchers)\n",
        "\n",
        "            # Stop if we have enough researchers\n",
        "            if len(all_researchers) >= max_researchers:\n",
        "                all_researchers = all_researchers[:max_researchers]  # Trim excess\n",
        "                break\n",
        "\n",
        "            # Get next cursor from meta\n",
        "            cursor = response.get('meta', {}).get('next_cursor')\n",
        "\n",
        "            if not cursor:  # No more pages\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching researchers: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    return all_researchers\n",
        "\n",
        "def get_researcher_works(researcher_id):\n",
        "    \"\"\"Get all works for a researcher using cursor pagination\"\"\"\n",
        "    clean_id = researcher_id.split('/')[-1]\n",
        "\n",
        "    base_params = {\n",
        "        'filter': f'author.id:{clean_id}',\n",
        "        'per-page': 200,\n",
        "        'sort': 'cited_by_count:desc'\n",
        "    }\n",
        "\n",
        "    all_works = []\n",
        "    cursor = '*'  # Initial cursor\n",
        "\n",
        "    while cursor:\n",
        "        try:\n",
        "            params = base_params.copy()\n",
        "            params['cursor'] = cursor\n",
        "\n",
        "            response = call_openalex_api('works', params)\n",
        "\n",
        "            if not response or 'results' not in response:\n",
        "                break\n",
        "\n",
        "            works = response['results']\n",
        "            if not works:\n",
        "                break\n",
        "\n",
        "            all_works.extend(works)\n",
        "\n",
        "            # Get next cursor from meta\n",
        "            cursor = response.get('meta', {}).get('next_cursor')\n",
        "\n",
        "            if not cursor:  # No more pages\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching works for researcher {clean_id}: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    return all_works\n",
        "\n",
        "def get_top_collaborators(works, researcher_id):\n",
        "    \"\"\"Get top 5 collaborators for a researcher based on co-authorship\"\"\"\n",
        "    collaborator_counts = Counter()\n",
        "\n",
        "    for work in works:\n",
        "        for authorship in work.get('authorships', []):\n",
        "            coauthor_id = authorship.get('author', {}).get('id')\n",
        "            if coauthor_id and coauthor_id != researcher_id:\n",
        "                collaborator_counts[coauthor_id] += 1\n",
        "\n",
        "    # Return top 5 collaborator IDs\n",
        "    return [collab_id for collab_id, _ in collaborator_counts.most_common(5)]\n",
        "\n",
        "def fetch_texas_state_researchers():\n",
        "    \"\"\"Fetch and process researchers affiliated with Texas State University\"\"\"\n",
        "    # Get Texas State University ID\n",
        "    texas_state_id = get_texas_state_id()\n",
        "    if not texas_state_id:\n",
        "        print(\"Could not find Texas State University ID\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found Texas State University ID: {texas_state_id}\")\n",
        "\n",
        "    # Fetch top 500 cited researchers affiliated with Texas State University\n",
        "    print(\"Fetching top 500 cited researchers from Texas State University...\")\n",
        "    researchers = fetch_top_cited_researchers(texas_state_id, max_researchers=500)\n",
        "\n",
        "    if not researchers:\n",
        "        print(\"Failed to fetch researchers\")\n",
        "        return\n",
        "\n",
        "    researchers_data = []\n",
        "    current_year = datetime.now().year\n",
        "\n",
        "    print(\"\\nProcessing researcher data...\")\n",
        "    for researcher in tqdm(researchers):\n",
        "        try:\n",
        "            # Basic info\n",
        "            researcher_info = {\n",
        "                'researcher_id': researcher['id'],\n",
        "                'researcher_name': researcher['display_name'],\n",
        "                'total_citations': researcher['cited_by_count'],\n",
        "                'total_works': researcher['works_count'],\n",
        "                'h_index': researcher.get('summary_stats', {}).get('h_index', 0),\n",
        "                'i10_index': researcher.get('summary_stats', {}).get('i10_index', 0)\n",
        "            }\n",
        "\n",
        "            # Add concepts\n",
        "            concepts = researcher.get('x_concepts', [])\n",
        "            for i in range(2):\n",
        "                if i < len(concepts):\n",
        "                    researcher_info[f'concept_{i+1}'] = concepts[i]['display_name']\n",
        "                    researcher_info[f'concept_{i+1}_score'] = concepts[i]['score']\n",
        "                else:\n",
        "                    researcher_info[f'concept_{i+1}'] = None\n",
        "                    researcher_info[f'concept_{i+1}_score'] = None\n",
        "\n",
        "            # Get works with cursor pagination\n",
        "            works = get_researcher_works(researcher['id'])\n",
        "\n",
        "            if works:\n",
        "                # Years active\n",
        "                publication_years = [w['publication_year'] for w in works if w.get('publication_year')]\n",
        "                if publication_years:\n",
        "                    researcher_info['years_active'] = max(publication_years) - min(publication_years) + 1\n",
        "                else:\n",
        "                    researcher_info['years_active'] = 0\n",
        "\n",
        "                # Recent works and citations\n",
        "                recent_works = [w for w in works if w.get('publication_year', 0) >= (current_year - 5)]\n",
        "                researcher_info['recent_works_count'] = len(recent_works)\n",
        "                researcher_info['recent_citations'] = sum(w.get('cited_by_count', 0) for w in recent_works)\n",
        "\n",
        "                # Unique venues\n",
        "                venues = set()\n",
        "                for work in works:\n",
        "                    if work.get('primary_location') and work['primary_location'].get('source'):\n",
        "                        venue = work['primary_location']['source'].get('display_name')\n",
        "                        if venue:\n",
        "                            venues.add(venue)\n",
        "                researcher_info['unique_venues'] = len(venues)\n",
        "\n",
        "                # Average coauthors\n",
        "                total_coauthors = sum(len(w.get('authorships', [])) - 1 for w in works)\n",
        "                researcher_info['avg_coauthors'] = total_coauthors / len(works) if works else 0\n",
        "\n",
        "                # Open access ratio\n",
        "                oa_works = sum(1 for w in works if w.get('open_access', {}).get('is_oa', False))\n",
        "                researcher_info['open_access_ratio'] = oa_works / len(works) if works else 0\n",
        "\n",
        "                # Top 5 works (already sorted by cited_by_count from API)\n",
        "                top_works = works[:5]\n",
        "                for i, work in enumerate(top_works, 1):\n",
        "                    researcher_info[f'top_work_{i}_id'] = work['id']\n",
        "                    researcher_info[f'top_work_{i}_type'] = work['type']\n",
        "                    researcher_info[f'top_work_{i}_is_oa'] = work['open_access']['is_oa']\n",
        "                    researcher_info[f'top_work_{i}_keywords'] = ','.join([c['display_name'] for c in work.get('concepts', [])[:5]])\n",
        "\n",
        "                    if work.get('primary_location') and work['primary_location'].get('source'):\n",
        "                        researcher_info[f'top_work_{i}_source'] = work['primary_location']['source'].get('display_name', '')\n",
        "                    else:\n",
        "                        researcher_info[f'top_work_{i}_source'] = ''\n",
        "\n",
        "                # Fill in missing top works\n",
        "                for i in range(len(top_works) + 1, 6):\n",
        "                    researcher_info[f'top_work_{i}_id'] = None\n",
        "                    researcher_info[f'top_work_{i}_type'] = None\n",
        "                    researcher_info[f'top_work_{i}_is_oa'] = None\n",
        "                    researcher_info[f'top_work_{i}_keywords'] = None\n",
        "                    researcher_info[f'top_work_{i}_source'] = None\n",
        "\n",
        "                # Top collaborators\n",
        "                top_collaborators = get_top_collaborators(works, researcher['id'])\n",
        "                for i, collab_id in enumerate(top_collaborators, 1):\n",
        "                    researcher_info[f'top_collaborator_{i}'] = collab_id\n",
        "\n",
        "                # Fill in missing collaborators\n",
        "                for i in range(len(top_collaborators) + 1, 6):\n",
        "                    researcher_info[f'top_collaborator_{i}'] = None\n",
        "\n",
        "            researchers_data.append(researcher_info)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing researcher {researcher.get('id')}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Convert to dataframe and save\n",
        "    df_researchers = pd.DataFrame(researchers_data)\n",
        "    df_researchers.to_csv('top_500_researchers.csv', index=False)\n",
        "\n",
        "    print(\"\\nTop 500 Researchers CSV head:\")\n",
        "    print(df_researchers.head())\n",
        "\n",
        "    print(f\"\\nNumber of researchers: {len(df_researchers)}\")\n",
        "    print(f\"Number of columns: {len(df_researchers.columns)}\")\n",
        "    print(\"\\nColumn names:\")\n",
        "    print(df_researchers.columns.tolist())\n",
        "\n",
        "    return df_researchers\n",
        "\n",
        "# Generate the researchers CSV\n",
        "df_researchers = fetch_texas_state_researchers()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtrQ6IvyPM4s"
      },
      "outputs": [],
      "source": [
        "df_researchers = pd.read_csv('top_500_researchers.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "JYvyq6XYOogR",
        "outputId": "185c3f2b-c998-4016-bba5-116e97bcdaac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_researchers"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f27e6e5a-abf4-4d33-9a10-eb0fd4dba82f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>researcher_id</th>\n",
              "      <th>researcher_name</th>\n",
              "      <th>total_citations</th>\n",
              "      <th>total_works</th>\n",
              "      <th>h_index</th>\n",
              "      <th>i10_index</th>\n",
              "      <th>concept_1</th>\n",
              "      <th>concept_1_score</th>\n",
              "      <th>concept_2</th>\n",
              "      <th>concept_2_score</th>\n",
              "      <th>...</th>\n",
              "      <th>top_work_5_id</th>\n",
              "      <th>top_work_5_type</th>\n",
              "      <th>top_work_5_is_oa</th>\n",
              "      <th>top_work_5_keywords</th>\n",
              "      <th>top_work_5_source</th>\n",
              "      <th>top_collaborator_1</th>\n",
              "      <th>top_collaborator_2</th>\n",
              "      <th>top_collaborator_3</th>\n",
              "      <th>top_collaborator_4</th>\n",
              "      <th>top_collaborator_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://openalex.org/A5046299069</td>\n",
              "      <td>Larry R. Price</td>\n",
              "      <td>26301</td>\n",
              "      <td>208</td>\n",
              "      <td>52</td>\n",
              "      <td>108</td>\n",
              "      <td>Computer science</td>\n",
              "      <td>73.1</td>\n",
              "      <td>Mathematics</td>\n",
              "      <td>70.7</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W2025106538</td>\n",
              "      <td>article</td>\n",
              "      <td>False</td>\n",
              "      <td>Psychology,Exposure therapy,Virtual reality,Ps...</td>\n",
              "      <td>Journal of Consulting and Clinical Psychology</td>\n",
              "      <td>https://openalex.org/A5019375929</td>\n",
              "      <td>https://openalex.org/A5009004096</td>\n",
              "      <td>https://openalex.org/A5101870896</td>\n",
              "      <td>https://openalex.org/A5085670077</td>\n",
              "      <td>https://openalex.org/A5107483970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://openalex.org/A5039371296</td>\n",
              "      <td>Michael A. Huston</td>\n",
              "      <td>21477</td>\n",
              "      <td>93</td>\n",
              "      <td>43</td>\n",
              "      <td>61</td>\n",
              "      <td>Biology</td>\n",
              "      <td>93.5</td>\n",
              "      <td>Ecology</td>\n",
              "      <td>86.0</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W2088443113</td>\n",
              "      <td>article</td>\n",
              "      <td>False</td>\n",
              "      <td>Microsite,Facilitation,Competition (biology),C...</td>\n",
              "      <td>Ecology</td>\n",
              "      <td>https://openalex.org/A5024934767</td>\n",
              "      <td>https://openalex.org/A5110483019</td>\n",
              "      <td>https://openalex.org/A5038398105</td>\n",
              "      <td>https://openalex.org/A5008653559</td>\n",
              "      <td>https://openalex.org/A5103521151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://openalex.org/A5070163403</td>\n",
              "      <td>Marcus Felson</td>\n",
              "      <td>21278</td>\n",
              "      <td>161</td>\n",
              "      <td>40</td>\n",
              "      <td>70</td>\n",
              "      <td>Sociology</td>\n",
              "      <td>72.7</td>\n",
              "      <td>Psychology</td>\n",
              "      <td>65.2</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W2311383940</td>\n",
              "      <td>article</td>\n",
              "      <td>False</td>\n",
              "      <td>Consumption (sociology),Sociology,Computer sci...</td>\n",
              "      <td>American Behavioral Scientist</td>\n",
              "      <td>https://openalex.org/A5046958460</td>\n",
              "      <td>https://openalex.org/A5102936013</td>\n",
              "      <td>https://openalex.org/A5037722191</td>\n",
              "      <td>https://openalex.org/A5109563801</td>\n",
              "      <td>https://openalex.org/A5072647442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://openalex.org/A5017593645</td>\n",
              "      <td>Togay Ozbakkaloglu</td>\n",
              "      <td>18853</td>\n",
              "      <td>345</td>\n",
              "      <td>75</td>\n",
              "      <td>207</td>\n",
              "      <td>Materials science</td>\n",
              "      <td>95.9</td>\n",
              "      <td>Composite material</td>\n",
              "      <td>95.1</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W2330198871</td>\n",
              "      <td>review</td>\n",
              "      <td>False</td>\n",
              "      <td>Materials science,Shrinkage,Flexural strength,...</td>\n",
              "      <td>Journal of Materials Science</td>\n",
              "      <td>https://openalex.org/A5082132566</td>\n",
              "      <td>https://openalex.org/A5043329482</td>\n",
              "      <td>https://openalex.org/A5040407357</td>\n",
              "      <td>https://openalex.org/A5011064916</td>\n",
              "      <td>https://openalex.org/A5019907987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://openalex.org/A5048215687</td>\n",
              "      <td>Eric Kirby</td>\n",
              "      <td>12428</td>\n",
              "      <td>278</td>\n",
              "      <td>49</td>\n",
              "      <td>88</td>\n",
              "      <td>Geology</td>\n",
              "      <td>93.2</td>\n",
              "      <td>Biology</td>\n",
              "      <td>87.8</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W2145347294</td>\n",
              "      <td>article</td>\n",
              "      <td>True</td>\n",
              "      <td>Thermochronology,Geology,Denudation,Fission tr...</td>\n",
              "      <td>Tectonics</td>\n",
              "      <td>https://openalex.org/A5038349665</td>\n",
              "      <td>https://openalex.org/A5090086069</td>\n",
              "      <td>https://openalex.org/A5100685756</td>\n",
              "      <td>https://openalex.org/A5038670501</td>\n",
              "      <td>https://openalex.org/A5009378840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>https://openalex.org/A5023485684</td>\n",
              "      <td>Sarah A. Blue</td>\n",
              "      <td>495</td>\n",
              "      <td>40</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Political science</td>\n",
              "      <td>87.5</td>\n",
              "      <td>Sociology</td>\n",
              "      <td>72.5</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W3128923529</td>\n",
              "      <td>article</td>\n",
              "      <td>True</td>\n",
              "      <td>Refugee,Precarity,Political science,Immigratio...</td>\n",
              "      <td>Social Sciences</td>\n",
              "      <td>https://openalex.org/A5033260789</td>\n",
              "      <td>https://openalex.org/A5061971733</td>\n",
              "      <td>https://openalex.org/A5071631028</td>\n",
              "      <td>https://openalex.org/A5077134305</td>\n",
              "      <td>https://openalex.org/A5090006328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>https://openalex.org/A5090287107</td>\n",
              "      <td>Nestor Guillen</td>\n",
              "      <td>494</td>\n",
              "      <td>61</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>Mathematics</td>\n",
              "      <td>98.4</td>\n",
              "      <td>Mathematical analysis</td>\n",
              "      <td>86.9</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W2043066177</td>\n",
              "      <td>article</td>\n",
              "      <td>True</td>\n",
              "      <td>Mathematics,Obstacle problem,Hypersurface,Dime...</td>\n",
              "      <td>Calculus of Variations and Partial Differentia...</td>\n",
              "      <td>https://openalex.org/A5008620763</td>\n",
              "      <td>https://openalex.org/A5004919774</td>\n",
              "      <td>https://openalex.org/A5052239059</td>\n",
              "      <td>https://openalex.org/A5113182229</td>\n",
              "      <td>https://openalex.org/A5046772699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>https://openalex.org/A5037599311</td>\n",
              "      <td>Bob Edward Vásquez</td>\n",
              "      <td>492</td>\n",
              "      <td>18</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>Psychology</td>\n",
              "      <td>94.4</td>\n",
              "      <td>Political science</td>\n",
              "      <td>88.9</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W2005094432</td>\n",
              "      <td>article</td>\n",
              "      <td>False</td>\n",
              "      <td>Juvenile delinquency,Friendship,Closeness,Psyc...</td>\n",
              "      <td>Journal of Criminal Justice</td>\n",
              "      <td>https://openalex.org/A5069510426</td>\n",
              "      <td>https://openalex.org/A5055937408</td>\n",
              "      <td>https://openalex.org/A5038854444</td>\n",
              "      <td>https://openalex.org/A5030063444</td>\n",
              "      <td>https://openalex.org/A5063852285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>https://openalex.org/A5005882875</td>\n",
              "      <td>Darrell L. Ward</td>\n",
              "      <td>491</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>Computer science</td>\n",
              "      <td>80.0</td>\n",
              "      <td>Programming language</td>\n",
              "      <td>48.0</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W1537711190</td>\n",
              "      <td>article</td>\n",
              "      <td>False</td>\n",
              "      <td>Computer science,Programming language,Computer...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://openalex.org/A5113668156</td>\n",
              "      <td>https://openalex.org/A5078340012</td>\n",
              "      <td>https://openalex.org/A5073304952</td>\n",
              "      <td>https://openalex.org/A5043121653</td>\n",
              "      <td>https://openalex.org/A5074662740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>https://openalex.org/A5030319348</td>\n",
              "      <td>Jonathan Anderson</td>\n",
              "      <td>490</td>\n",
              "      <td>37</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>Materials science</td>\n",
              "      <td>97.3</td>\n",
              "      <td>Physics</td>\n",
              "      <td>94.6</td>\n",
              "      <td>...</td>\n",
              "      <td>https://openalex.org/W2395536243</td>\n",
              "      <td>article</td>\n",
              "      <td>True</td>\n",
              "      <td>Materials science,Wafer,Diamond,Raman spectros...</td>\n",
              "      <td>Applied Physics Letters</td>\n",
              "      <td>https://openalex.org/A5063322161</td>\n",
              "      <td>https://openalex.org/A5083363281</td>\n",
              "      <td>https://openalex.org/A5040285787</td>\n",
              "      <td>https://openalex.org/A5101660894</td>\n",
              "      <td>https://openalex.org/A5032695726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f27e6e5a-abf4-4d33-9a10-eb0fd4dba82f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f27e6e5a-abf4-4d33-9a10-eb0fd4dba82f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f27e6e5a-abf4-4d33-9a10-eb0fd4dba82f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b5907992-d6b5-4b7a-8171-c88aa9fdb333\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5907992-d6b5-4b7a-8171-c88aa9fdb333')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b5907992-d6b5-4b7a-8171-c88aa9fdb333 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_faa5c872-4746-4eaa-a9fa-213c373b3d5a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_researchers')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_faa5c872-4746-4eaa-a9fa-213c373b3d5a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_researchers');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                        researcher_id     researcher_name  total_citations  \\\n",
              "0    https://openalex.org/A5046299069      Larry R. Price            26301   \n",
              "1    https://openalex.org/A5039371296   Michael A. Huston            21477   \n",
              "2    https://openalex.org/A5070163403       Marcus Felson            21278   \n",
              "3    https://openalex.org/A5017593645  Togay Ozbakkaloglu            18853   \n",
              "4    https://openalex.org/A5048215687          Eric Kirby            12428   \n",
              "..                                ...                 ...              ...   \n",
              "495  https://openalex.org/A5023485684       Sarah A. Blue              495   \n",
              "496  https://openalex.org/A5090287107      Nestor Guillen              494   \n",
              "497  https://openalex.org/A5037599311  Bob Edward Vásquez              492   \n",
              "498  https://openalex.org/A5005882875     Darrell L. Ward              491   \n",
              "499  https://openalex.org/A5030319348   Jonathan Anderson              490   \n",
              "\n",
              "     total_works  h_index  i10_index          concept_1  concept_1_score  \\\n",
              "0            208       52        108   Computer science             73.1   \n",
              "1             93       43         61            Biology             93.5   \n",
              "2            161       40         70          Sociology             72.7   \n",
              "3            345       75        207  Materials science             95.9   \n",
              "4            278       49         88            Geology             93.2   \n",
              "..           ...      ...        ...                ...              ...   \n",
              "495           40       11         12  Political science             87.5   \n",
              "496           61       11         14        Mathematics             98.4   \n",
              "497           18        7          7         Psychology             94.4   \n",
              "498           25        4          3   Computer science             80.0   \n",
              "499           37       11         15  Materials science             97.3   \n",
              "\n",
              "                 concept_2  concept_2_score  ...  \\\n",
              "0              Mathematics             70.7  ...   \n",
              "1                  Ecology             86.0  ...   \n",
              "2               Psychology             65.2  ...   \n",
              "3       Composite material             95.1  ...   \n",
              "4                  Biology             87.8  ...   \n",
              "..                     ...              ...  ...   \n",
              "495              Sociology             72.5  ...   \n",
              "496  Mathematical analysis             86.9  ...   \n",
              "497      Political science             88.9  ...   \n",
              "498   Programming language             48.0  ...   \n",
              "499                Physics             94.6  ...   \n",
              "\n",
              "                        top_work_5_id  top_work_5_type  top_work_5_is_oa  \\\n",
              "0    https://openalex.org/W2025106538          article             False   \n",
              "1    https://openalex.org/W2088443113          article             False   \n",
              "2    https://openalex.org/W2311383940          article             False   \n",
              "3    https://openalex.org/W2330198871           review             False   \n",
              "4    https://openalex.org/W2145347294          article              True   \n",
              "..                                ...              ...               ...   \n",
              "495  https://openalex.org/W3128923529          article              True   \n",
              "496  https://openalex.org/W2043066177          article              True   \n",
              "497  https://openalex.org/W2005094432          article             False   \n",
              "498  https://openalex.org/W1537711190          article             False   \n",
              "499  https://openalex.org/W2395536243          article              True   \n",
              "\n",
              "                                   top_work_5_keywords  \\\n",
              "0    Psychology,Exposure therapy,Virtual reality,Ps...   \n",
              "1    Microsite,Facilitation,Competition (biology),C...   \n",
              "2    Consumption (sociology),Sociology,Computer sci...   \n",
              "3    Materials science,Shrinkage,Flexural strength,...   \n",
              "4    Thermochronology,Geology,Denudation,Fission tr...   \n",
              "..                                                 ...   \n",
              "495  Refugee,Precarity,Political science,Immigratio...   \n",
              "496  Mathematics,Obstacle problem,Hypersurface,Dime...   \n",
              "497  Juvenile delinquency,Friendship,Closeness,Psyc...   \n",
              "498  Computer science,Programming language,Computer...   \n",
              "499  Materials science,Wafer,Diamond,Raman spectros...   \n",
              "\n",
              "                                     top_work_5_source  \\\n",
              "0        Journal of Consulting and Clinical Psychology   \n",
              "1                                              Ecology   \n",
              "2                        American Behavioral Scientist   \n",
              "3                         Journal of Materials Science   \n",
              "4                                            Tectonics   \n",
              "..                                                 ...   \n",
              "495                                    Social Sciences   \n",
              "496  Calculus of Variations and Partial Differentia...   \n",
              "497                        Journal of Criminal Justice   \n",
              "498                                                NaN   \n",
              "499                            Applied Physics Letters   \n",
              "\n",
              "                   top_collaborator_1                top_collaborator_2  \\\n",
              "0    https://openalex.org/A5019375929  https://openalex.org/A5009004096   \n",
              "1    https://openalex.org/A5024934767  https://openalex.org/A5110483019   \n",
              "2    https://openalex.org/A5046958460  https://openalex.org/A5102936013   \n",
              "3    https://openalex.org/A5082132566  https://openalex.org/A5043329482   \n",
              "4    https://openalex.org/A5038349665  https://openalex.org/A5090086069   \n",
              "..                                ...                               ...   \n",
              "495  https://openalex.org/A5033260789  https://openalex.org/A5061971733   \n",
              "496  https://openalex.org/A5008620763  https://openalex.org/A5004919774   \n",
              "497  https://openalex.org/A5069510426  https://openalex.org/A5055937408   \n",
              "498  https://openalex.org/A5113668156  https://openalex.org/A5078340012   \n",
              "499  https://openalex.org/A5063322161  https://openalex.org/A5083363281   \n",
              "\n",
              "                   top_collaborator_3                top_collaborator_4  \\\n",
              "0    https://openalex.org/A5101870896  https://openalex.org/A5085670077   \n",
              "1    https://openalex.org/A5038398105  https://openalex.org/A5008653559   \n",
              "2    https://openalex.org/A5037722191  https://openalex.org/A5109563801   \n",
              "3    https://openalex.org/A5040407357  https://openalex.org/A5011064916   \n",
              "4    https://openalex.org/A5100685756  https://openalex.org/A5038670501   \n",
              "..                                ...                               ...   \n",
              "495  https://openalex.org/A5071631028  https://openalex.org/A5077134305   \n",
              "496  https://openalex.org/A5052239059  https://openalex.org/A5113182229   \n",
              "497  https://openalex.org/A5038854444  https://openalex.org/A5030063444   \n",
              "498  https://openalex.org/A5073304952  https://openalex.org/A5043121653   \n",
              "499  https://openalex.org/A5040285787  https://openalex.org/A5101660894   \n",
              "\n",
              "                   top_collaborator_5  \n",
              "0    https://openalex.org/A5107483970  \n",
              "1    https://openalex.org/A5103521151  \n",
              "2    https://openalex.org/A5072647442  \n",
              "3    https://openalex.org/A5019907987  \n",
              "4    https://openalex.org/A5009378840  \n",
              "..                                ...  \n",
              "495  https://openalex.org/A5090006328  \n",
              "496  https://openalex.org/A5046772699  \n",
              "497  https://openalex.org/A5063852285  \n",
              "498  https://openalex.org/A5074662740  \n",
              "499  https://openalex.org/A5032695726  \n",
              "\n",
              "[500 rows x 46 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_researchers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XG2P-VKmYGYP",
        "outputId": "bf5027c5-94c1-4265-cc6c-fa81a7c7fbc1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>researcher_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>researcher_name</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_citations</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_works</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h_index</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i10_index</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concept_1</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concept_1_score</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concept_2</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concept_2_score</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>years_active</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recent_works_count</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recent_citations</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique_venues</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avg_coauthors</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>open_access_ratio</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_1_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_1_type</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_1_is_oa</th>\n",
              "      <td>bool</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_1_keywords</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_1_source</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_2_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_2_type</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_2_is_oa</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_2_keywords</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_2_source</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_3_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_3_type</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_3_is_oa</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_3_keywords</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_3_source</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_4_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_4_type</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_4_is_oa</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_4_keywords</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_4_source</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_5_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_5_type</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_5_is_oa</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_5_keywords</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_work_5_source</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_collaborator_1</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_collaborator_2</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_collaborator_3</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_collaborator_4</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_collaborator_5</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "researcher_id           object\n",
              "researcher_name         object\n",
              "total_citations          int64\n",
              "total_works              int64\n",
              "h_index                  int64\n",
              "i10_index                int64\n",
              "concept_1               object\n",
              "concept_1_score        float64\n",
              "concept_2               object\n",
              "concept_2_score        float64\n",
              "years_active             int64\n",
              "recent_works_count       int64\n",
              "recent_citations         int64\n",
              "unique_venues            int64\n",
              "avg_coauthors          float64\n",
              "open_access_ratio      float64\n",
              "top_work_1_id           object\n",
              "top_work_1_type         object\n",
              "top_work_1_is_oa          bool\n",
              "top_work_1_keywords     object\n",
              "top_work_1_source       object\n",
              "top_work_2_id           object\n",
              "top_work_2_type         object\n",
              "top_work_2_is_oa        object\n",
              "top_work_2_keywords     object\n",
              "top_work_2_source       object\n",
              "top_work_3_id           object\n",
              "top_work_3_type         object\n",
              "top_work_3_is_oa        object\n",
              "top_work_3_keywords     object\n",
              "top_work_3_source       object\n",
              "top_work_4_id           object\n",
              "top_work_4_type         object\n",
              "top_work_4_is_oa        object\n",
              "top_work_4_keywords     object\n",
              "top_work_4_source       object\n",
              "top_work_5_id           object\n",
              "top_work_5_type         object\n",
              "top_work_5_is_oa        object\n",
              "top_work_5_keywords     object\n",
              "top_work_5_source       object\n",
              "top_collaborator_1      object\n",
              "top_collaborator_2      object\n",
              "top_collaborator_3      object\n",
              "top_collaborator_4      object\n",
              "top_collaborator_5      object\n",
              "dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_researchers.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNHgnzMqPIjI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fLtKUopYIjd",
        "outputId": "36b28d9d-7e39-48b1-e6d2-64fced20fa38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 46)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_researchers.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZayhB1MYhp5"
      },
      "outputs": [],
      "source": [
        "grants = pd.read_csv('grants.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "BiproKPGZehD",
        "outputId": "f3c4efb6-9b2d-4535-8688-83574d84a8df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>opportunity_id</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opportunity_number</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opportunity_title</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opportunity_status</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agency</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agency_code</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agency_name</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category_explanation</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>award_ceiling</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>award_floor</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>estimated_total_funding</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>expected_awards</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>post_date</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>close_date</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>funding_categories</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>applicant_types</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>funding_instruments</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>summary_description</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eligibility_description</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "opportunity_id               int64\n",
              "opportunity_number          object\n",
              "opportunity_title           object\n",
              "opportunity_status          object\n",
              "agency                      object\n",
              "agency_code                 object\n",
              "agency_name                 object\n",
              "category                    object\n",
              "category_explanation        object\n",
              "award_ceiling              float64\n",
              "award_floor                float64\n",
              "estimated_total_funding    float64\n",
              "expected_awards            float64\n",
              "post_date                   object\n",
              "close_date                  object\n",
              "funding_categories          object\n",
              "applicant_types             object\n",
              "funding_instruments         object\n",
              "summary_description         object\n",
              "eligibility_description     object\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grants.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAweDginZkeX",
        "outputId": "1c00a6a1-1492-4a4c-ff28-35d1b5e5ce82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 20)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grants.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScFZcy30Zlve",
        "outputId": "aea494d3-3a28-4015-eb7c-32a6aa13ce09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in researchers dataset:\n",
            "researcher_id           0\n",
            "researcher_name         0\n",
            "total_citations         0\n",
            "total_works             0\n",
            "h_index                 0\n",
            "i10_index               0\n",
            "concept_1               0\n",
            "concept_1_score         0\n",
            "concept_2               0\n",
            "concept_2_score         0\n",
            "years_active            0\n",
            "recent_works_count      0\n",
            "recent_citations        0\n",
            "unique_venues           0\n",
            "avg_coauthors           0\n",
            "open_access_ratio       0\n",
            "top_work_1_id           0\n",
            "top_work_1_type         0\n",
            "top_work_1_is_oa        0\n",
            "top_work_1_keywords     0\n",
            "top_work_1_source      24\n",
            "top_work_2_id           5\n",
            "top_work_2_type         5\n",
            "top_work_2_is_oa        5\n",
            "top_work_2_keywords     5\n",
            "top_work_2_source      34\n",
            "top_work_3_id           5\n",
            "top_work_3_type         5\n",
            "top_work_3_is_oa        5\n",
            "top_work_3_keywords     5\n",
            "top_work_3_source      33\n",
            "top_work_4_id           6\n",
            "top_work_4_type         6\n",
            "top_work_4_is_oa        6\n",
            "top_work_4_keywords     6\n",
            "top_work_4_source      38\n",
            "top_work_5_id           8\n",
            "top_work_5_type         8\n",
            "top_work_5_is_oa        8\n",
            "top_work_5_keywords     8\n",
            "top_work_5_source      43\n",
            "top_collaborator_1      0\n",
            "top_collaborator_2      0\n",
            "top_collaborator_3      1\n",
            "top_collaborator_4      1\n",
            "top_collaborator_5      2\n",
            "dtype: int64\n",
            "\n",
            "Percentage of missing values:\n",
            "researcher_id          0.0\n",
            "researcher_name        0.0\n",
            "total_citations        0.0\n",
            "total_works            0.0\n",
            "h_index                0.0\n",
            "i10_index              0.0\n",
            "concept_1              0.0\n",
            "concept_1_score        0.0\n",
            "concept_2              0.0\n",
            "concept_2_score        0.0\n",
            "years_active           0.0\n",
            "recent_works_count     0.0\n",
            "recent_citations       0.0\n",
            "unique_venues          0.0\n",
            "avg_coauthors          0.0\n",
            "open_access_ratio      0.0\n",
            "top_work_1_id          0.0\n",
            "top_work_1_type        0.0\n",
            "top_work_1_is_oa       0.0\n",
            "top_work_1_keywords    0.0\n",
            "top_work_1_source      4.8\n",
            "top_work_2_id          1.0\n",
            "top_work_2_type        1.0\n",
            "top_work_2_is_oa       1.0\n",
            "top_work_2_keywords    1.0\n",
            "top_work_2_source      6.8\n",
            "top_work_3_id          1.0\n",
            "top_work_3_type        1.0\n",
            "top_work_3_is_oa       1.0\n",
            "top_work_3_keywords    1.0\n",
            "top_work_3_source      6.6\n",
            "top_work_4_id          1.2\n",
            "top_work_4_type        1.2\n",
            "top_work_4_is_oa       1.2\n",
            "top_work_4_keywords    1.2\n",
            "top_work_4_source      7.6\n",
            "top_work_5_id          1.6\n",
            "top_work_5_type        1.6\n",
            "top_work_5_is_oa       1.6\n",
            "top_work_5_keywords    1.6\n",
            "top_work_5_source      8.6\n",
            "top_collaborator_1     0.0\n",
            "top_collaborator_2     0.0\n",
            "top_collaborator_3     0.2\n",
            "top_collaborator_4     0.2\n",
            "top_collaborator_5     0.4\n",
            "dtype: float64\n",
            "\n",
            "Missing values in grants dataset:\n",
            "opportunity_id                0\n",
            "opportunity_number            0\n",
            "opportunity_title             0\n",
            "opportunity_status            0\n",
            "agency                        0\n",
            "agency_code                   0\n",
            "agency_name                   0\n",
            "category                      1\n",
            "category_explanation       4526\n",
            "award_ceiling                 0\n",
            "award_floor                   0\n",
            "estimated_total_funding       0\n",
            "expected_awards               0\n",
            "post_date                     0\n",
            "close_date                  409\n",
            "funding_categories            4\n",
            "applicant_types               4\n",
            "funding_instruments           4\n",
            "summary_description           0\n",
            "eligibility_description    1530\n",
            "dtype: int64\n",
            "\n",
            "Percentage of missing values:\n",
            "opportunity_id              0.00\n",
            "opportunity_number          0.00\n",
            "opportunity_title           0.00\n",
            "opportunity_status          0.00\n",
            "agency                      0.00\n",
            "agency_code                 0.00\n",
            "agency_name                 0.00\n",
            "category                    0.02\n",
            "category_explanation       90.52\n",
            "award_ceiling               0.00\n",
            "award_floor                 0.00\n",
            "estimated_total_funding     0.00\n",
            "expected_awards             0.00\n",
            "post_date                   0.00\n",
            "close_date                  8.18\n",
            "funding_categories          0.08\n",
            "applicant_types             0.08\n",
            "funding_instruments         0.08\n",
            "summary_description         0.00\n",
            "eligibility_description    30.60\n",
            "dtype: float64\n",
            "\n",
            "After cleaning - Missing values in researchers dataset:\n",
            "0\n",
            "\n",
            "After cleaning - Missing values in grants dataset:\n",
            "0\n",
            "\n",
            "Data Quality Report:\n",
            "\n",
            "Researchers Dataset:\n",
            "Original shape: (500, 46)\n",
            "Cleaned shape: (500, 46)\n",
            "\n",
            "Grants Dataset:\n",
            "Original shape: (5000, 20)\n",
            "Cleaned shape: (5000, 20)\n",
            "\n",
            "Sample statistics after cleaning:\n",
            "\n",
            "Researchers numeric columns:\n",
            "       total_citations  total_works  h_index  i10_index  concept_1_score  \\\n",
            "count           500.00       500.00   500.00     500.00           500.00   \n",
            "mean           1869.27        71.55    17.36      27.13            89.11   \n",
            "std            2496.28        58.80     9.21      23.74            11.69   \n",
            "min             490.00         1.00     1.00       1.00            38.50   \n",
            "25%             703.75        33.00    12.00      13.00            82.18   \n",
            "50%            1038.50        54.00    15.00      19.00            92.15   \n",
            "75%            2013.75        89.00    21.00      32.00            98.00   \n",
            "max           26301.00       352.00    75.00     207.00           128.00   \n",
            "\n",
            "       concept_2_score  years_active  recent_works_count  recent_citations  \\\n",
            "count           500.00        500.00              500.00            500.00   \n",
            "mean             79.77         36.39               14.74            107.82   \n",
            "std              14.05         25.59               22.32            322.79   \n",
            "min              32.80          1.00                0.00              0.00   \n",
            "25%              70.18         21.00                1.00              0.00   \n",
            "50%              80.90         31.00                7.50             23.50   \n",
            "75%              90.72         45.00               19.00             99.50   \n",
            "max             123.00        225.00              220.00           5487.00   \n",
            "\n",
            "       unique_venues  avg_coauthors  open_access_ratio  \n",
            "count         500.00         500.00             500.00  \n",
            "mean           28.46           3.52               0.26  \n",
            "std            18.09           2.51               0.21  \n",
            "min             1.00           0.40               0.00  \n",
            "25%            16.75           1.89               0.10  \n",
            "50%            24.00           2.91               0.21  \n",
            "75%            37.00           4.44               0.37  \n",
            "max           104.00          20.77               1.00  \n",
            "\n",
            "Grants numeric columns:\n",
            "       opportunity_id  award_ceiling   award_floor  estimated_total_funding  \\\n",
            "count         5000.00   5.000000e+03  5.000000e+03             5.000000e+03   \n",
            "mean         44692.56   3.198742e+06  8.727985e+05             8.805624e+06   \n",
            "std           2576.82   2.979877e+07  1.988934e+07             7.276693e+07   \n",
            "min          15936.00   0.000000e+00  0.000000e+00             0.000000e+00   \n",
            "25%          42814.25   0.000000e+00  0.000000e+00             0.000000e+00   \n",
            "50%          44584.50   6.000000e+04  0.000000e+00             1.000000e+05   \n",
            "75%          46723.00   4.500000e+05  5.000000e+03             2.000000e+06   \n",
            "max          48949.00   1.300000e+09  1.300000e+09             2.600000e+09   \n",
            "\n",
            "       expected_awards  \n",
            "count          5000.00  \n",
            "mean             82.49  \n",
            "std            3301.66  \n",
            "min               0.00  \n",
            "25%               0.00  \n",
            "50%               1.00  \n",
            "75%               4.00  \n",
            "max          175000.00  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load datasets\n",
        "researchers_df = pd.read_csv('top_500_researchers.csv')\n",
        "grants_df = pd.read_csv('grants.csv')\n",
        "\n",
        "# Check missing values in researchers dataset\n",
        "print(\"Missing values in researchers dataset:\")\n",
        "print(researchers_df.isnull().sum())\n",
        "print(\"\\nPercentage of missing values:\")\n",
        "print((researchers_df.isnull().sum() / len(researchers_df)) * 100)\n",
        "\n",
        "# Check missing values in grants dataset\n",
        "print(\"\\nMissing values in grants dataset:\")\n",
        "print(grants_df.isnull().sum())\n",
        "print(\"\\nPercentage of missing values:\")\n",
        "print((grants_df.isnull().sum() / len(grants_df)) * 100)\n",
        "\n",
        "# Handle missing values in researchers dataset\n",
        "def clean_researchers_df(df):\n",
        "    # Fill numeric columns with appropriate values\n",
        "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    df[numeric_cols] = df[numeric_cols].fillna(0)\n",
        "\n",
        "    # Fill object (string) columns\n",
        "    object_cols = df.select_dtypes(include=['object']).columns\n",
        "    df[object_cols] = df[object_cols].fillna('')\n",
        "\n",
        "    # Fix boolean columns\n",
        "    bool_cols = [col for col in df.columns if 'is_oa' in col]\n",
        "    df[bool_cols] = df[bool_cols].fillna(False)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Handle missing values in grants dataset\n",
        "def clean_grants_df(df):\n",
        "    # Fill numeric columns\n",
        "    df['award_ceiling'] = df['award_ceiling'].fillna(0)\n",
        "    df['award_floor'] = df['award_floor'].fillna(0)\n",
        "    df['estimated_total_funding'] = df['estimated_total_funding'].fillna(0)\n",
        "    df['expected_awards'] = df['expected_awards'].fillna(0)\n",
        "\n",
        "    # Fill categorical columns\n",
        "    categorical_cols = [\n",
        "        'opportunity_number', 'opportunity_title', 'opportunity_status',\n",
        "        'agency', 'agency_code', 'agency_name', 'category', 'category_explanation',\n",
        "        'funding_categories', 'applicant_types', 'funding_instruments'\n",
        "    ]\n",
        "    df[categorical_cols] = df[categorical_cols].fillna('')\n",
        "\n",
        "    # Fill date columns\n",
        "    date_cols = ['post_date', 'close_date']\n",
        "    df[date_cols] = df[date_cols].fillna('')\n",
        "\n",
        "    # Fill description fields\n",
        "    df['summary_description'] = df['summary_description'].fillna('')\n",
        "    df['eligibility_description'] = df['eligibility_description'].fillna('')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Clean both datasets\n",
        "researchers_clean = clean_researchers_df(researchers_df.copy())\n",
        "grants_clean = clean_grants_df(grants_df.copy())\n",
        "\n",
        "# Verify no missing values remain\n",
        "print(\"\\nAfter cleaning - Missing values in researchers dataset:\")\n",
        "print(researchers_clean.isnull().sum().sum())\n",
        "print(\"\\nAfter cleaning - Missing values in grants dataset:\")\n",
        "print(grants_clean.isnull().sum().sum())\n",
        "\n",
        "# Save cleaned datasets\n",
        "researchers_clean.to_csv('researchers_clean.csv', index=False)\n",
        "grants_clean.to_csv('grants_clean.csv', index=False)\n",
        "\n",
        "# Print data quality report\n",
        "print(\"\\nData Quality Report:\")\n",
        "print(\"\\nResearchers Dataset:\")\n",
        "print(f\"Original shape: {researchers_df.shape}\")\n",
        "print(f\"Cleaned shape: {researchers_clean.shape}\")\n",
        "print(\"\\nGrants Dataset:\")\n",
        "print(f\"Original shape: {grants_df.shape}\")\n",
        "print(f\"Cleaned shape: {grants_clean.shape}\")\n",
        "\n",
        "# Display sample statistics\n",
        "print(\"\\nSample statistics after cleaning:\")\n",
        "print(\"\\nResearchers numeric columns:\")\n",
        "print(researchers_clean.describe().round(2))\n",
        "print(\"\\nGrants numeric columns:\")\n",
        "print(grants_clean.describe().round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "05dlA1mOayIa",
        "outputId": "c54e180c-d05d-4163-b985-6efffdbf64c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   opportunity_id      opportunity_number  \\\n",
              "0           15936              07HQPA0028   \n",
              "1           15937    ED-GRANTS-070907-001   \n",
              "2           15939    ED-GRANTS-070907-002   \n",
              "3           15941       NNH07ZEA001N-EDL1   \n",
              "4           17675  CNCS-GRANTS-071307-001   \n",
              "\n",
              "                                   opportunity_title opportunity_status  \\\n",
              "0  Cooperative Ecosystem Studies Unit, Rocky Moun...           archived   \n",
              "1  Youth violence and related issues in persisten...           archived   \n",
              "2  State data collection; technical assistance CF...           archived   \n",
              "3        ROA 2007: A.6 Entry, Descent, and Landing 1           archived   \n",
              "4                               Volunteer Management           archived   \n",
              "\n",
              "      agency agency_code                                     agency_name  \\\n",
              "0  DOI-USGS1   DOI-USGS1                               Geological Survey   \n",
              "1         ED          ED                         Department of Education   \n",
              "2         ED          ED                         Department of Education   \n",
              "3    NASA-HQ     NASA-HQ                               NASA Headquarters   \n",
              "4       CNCS        CNCS  Corporation for National and Community Service   \n",
              "\n",
              "        category category_explanation  award_ceiling  award_floor  \\\n",
              "0  discretionary                  NaN        24957.0      24957.0   \n",
              "1  discretionary                  NaN            0.0          0.0   \n",
              "2  discretionary                  NaN       400000.0          0.0   \n",
              "3  discretionary                  NaN            0.0          0.0   \n",
              "4  discretionary                  NaN       200000.0      50000.0   \n",
              "\n",
              "   estimated_total_funding  expected_awards   post_date  close_date  \\\n",
              "0                  24957.0              1.0  2007-07-09  2007-07-19   \n",
              "1                8594000.0             13.0  2007-07-09  2007-08-08   \n",
              "2               13500000.0              0.0  2007-07-09  2007-08-23   \n",
              "3                      0.0              0.0  2007-07-09  2007-08-20   \n",
              "4                 800000.0              6.0  2007-07-13  2007-09-06   \n",
              "\n",
              "                                  funding_categories  \\\n",
              "0  science_technology_and_other_research_and_deve...   \n",
              "1                                          education   \n",
              "2                                          education   \n",
              "3  science_technology_and_other_research_and_deve...   \n",
              "4  disaster_prevention_and_relief,regional_develo...   \n",
              "\n",
              "                                     applicant_types  \\\n",
              "0                                              other   \n",
              "1                                              other   \n",
              "2                                              other   \n",
              "3                                       unrestricted   \n",
              "4  county_governments,nonprofits_non_higher_educa...   \n",
              "\n",
              "           funding_instruments  \\\n",
              "0        cooperative_agreement   \n",
              "1                        grant   \n",
              "2                        grant   \n",
              "3  cooperative_agreement,grant   \n",
              "4                        grant   \n",
              "\n",
              "                                 summary_description  \\\n",
              "0  The U.S. Geological Surveys is offering a coo...   \n",
              "1  Note:  Each funding opportunity description i...   \n",
              "2  Note:  Each funding opportunity description i...   \n",
              "3  The National Aeronautics and Space Administrat...   \n",
              "4  The Corporation for National and Community Ser...   \n",
              "\n",
              "                             eligibility_description  \n",
              "0  This financial assistance opportunity is being...  \n",
              "1  Eligible Applicants: LEAs in which at least on...  \n",
              "2  Note: Eligible entities must submit separate a...  \n",
              "3                                       Unrestricted  \n",
              "4  The Corporation wants to ensure that all eligi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8545ad9e-6f91-4794-aac1-a8275db5e331\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opportunity_id</th>\n",
              "      <th>opportunity_number</th>\n",
              "      <th>opportunity_title</th>\n",
              "      <th>opportunity_status</th>\n",
              "      <th>agency</th>\n",
              "      <th>agency_code</th>\n",
              "      <th>agency_name</th>\n",
              "      <th>category</th>\n",
              "      <th>category_explanation</th>\n",
              "      <th>award_ceiling</th>\n",
              "      <th>award_floor</th>\n",
              "      <th>estimated_total_funding</th>\n",
              "      <th>expected_awards</th>\n",
              "      <th>post_date</th>\n",
              "      <th>close_date</th>\n",
              "      <th>funding_categories</th>\n",
              "      <th>applicant_types</th>\n",
              "      <th>funding_instruments</th>\n",
              "      <th>summary_description</th>\n",
              "      <th>eligibility_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15936</td>\n",
              "      <td>07HQPA0028</td>\n",
              "      <td>Cooperative Ecosystem Studies Unit, Rocky Moun...</td>\n",
              "      <td>archived</td>\n",
              "      <td>DOI-USGS1</td>\n",
              "      <td>DOI-USGS1</td>\n",
              "      <td>Geological Survey</td>\n",
              "      <td>discretionary</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24957.0</td>\n",
              "      <td>24957.0</td>\n",
              "      <td>24957.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2007-07-09</td>\n",
              "      <td>2007-07-19</td>\n",
              "      <td>science_technology_and_other_research_and_deve...</td>\n",
              "      <td>other</td>\n",
              "      <td>cooperative_agreement</td>\n",
              "      <td>The U.S. Geological Surveys is offering a coo...</td>\n",
              "      <td>This financial assistance opportunity is being...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15937</td>\n",
              "      <td>ED-GRANTS-070907-001</td>\n",
              "      <td>Youth violence and related issues in persisten...</td>\n",
              "      <td>archived</td>\n",
              "      <td>ED</td>\n",
              "      <td>ED</td>\n",
              "      <td>Department of Education</td>\n",
              "      <td>discretionary</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8594000.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2007-07-09</td>\n",
              "      <td>2007-08-08</td>\n",
              "      <td>education</td>\n",
              "      <td>other</td>\n",
              "      <td>grant</td>\n",
              "      <td>Note:  Each funding opportunity description i...</td>\n",
              "      <td>Eligible Applicants: LEAs in which at least on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15939</td>\n",
              "      <td>ED-GRANTS-070907-002</td>\n",
              "      <td>State data collection; technical assistance CF...</td>\n",
              "      <td>archived</td>\n",
              "      <td>ED</td>\n",
              "      <td>ED</td>\n",
              "      <td>Department of Education</td>\n",
              "      <td>discretionary</td>\n",
              "      <td>NaN</td>\n",
              "      <td>400000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13500000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-07-09</td>\n",
              "      <td>2007-08-23</td>\n",
              "      <td>education</td>\n",
              "      <td>other</td>\n",
              "      <td>grant</td>\n",
              "      <td>Note:  Each funding opportunity description i...</td>\n",
              "      <td>Note: Eligible entities must submit separate a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15941</td>\n",
              "      <td>NNH07ZEA001N-EDL1</td>\n",
              "      <td>ROA 2007: A.6 Entry, Descent, and Landing 1</td>\n",
              "      <td>archived</td>\n",
              "      <td>NASA-HQ</td>\n",
              "      <td>NASA-HQ</td>\n",
              "      <td>NASA Headquarters</td>\n",
              "      <td>discretionary</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007-07-09</td>\n",
              "      <td>2007-08-20</td>\n",
              "      <td>science_technology_and_other_research_and_deve...</td>\n",
              "      <td>unrestricted</td>\n",
              "      <td>cooperative_agreement,grant</td>\n",
              "      <td>The National Aeronautics and Space Administrat...</td>\n",
              "      <td>Unrestricted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17675</td>\n",
              "      <td>CNCS-GRANTS-071307-001</td>\n",
              "      <td>Volunteer Management</td>\n",
              "      <td>archived</td>\n",
              "      <td>CNCS</td>\n",
              "      <td>CNCS</td>\n",
              "      <td>Corporation for National and Community Service</td>\n",
              "      <td>discretionary</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>800000.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2007-07-13</td>\n",
              "      <td>2007-09-06</td>\n",
              "      <td>disaster_prevention_and_relief,regional_develo...</td>\n",
              "      <td>county_governments,nonprofits_non_higher_educa...</td>\n",
              "      <td>grant</td>\n",
              "      <td>The Corporation for National and Community Ser...</td>\n",
              "      <td>The Corporation wants to ensure that all eligi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8545ad9e-6f91-4794-aac1-a8275db5e331')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8545ad9e-6f91-4794-aac1-a8275db5e331 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8545ad9e-6f91-4794-aac1-a8275db5e331');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-343bfba5-f5cc-48d0-8ab8-39292f069db1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-343bfba5-f5cc-48d0-8ab8-39292f069db1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-343bfba5-f5cc-48d0-8ab8-39292f069db1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "grants_df",
              "summary": "{\n  \"name\": \"grants_df\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"opportunity_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2576,\n        \"min\": 15936,\n        \"max\": 48949,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          43343,\n          44761,\n          44846\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opportunity_number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4990,\n        \"samples\": [\n          \"FR-5300-23\",\n          \"FTA-09002-TPM-UWR\",\n          \"RFA-AI-09-015\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opportunity_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4661,\n        \"samples\": [\n          \"Small Grants for Behavioral Research in Cancer Control (R03)\",\n          \"NIDA Research Education Grants in Drug Abuse and Addiction (R25)\",\n          \"FY 2009 National Scenic Byways Program Discretionary Grants\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opportunity_status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"archived\",\n          \"posted\",\n          \"closed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agency\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 229,\n        \"samples\": [\n          \"USDOT-IRS\",\n          \"USAID-COL\",\n          \"DOD-DARPA-MTO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agency_code\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 229,\n        \"samples\": [\n          \"USDOT-IRS\",\n          \"USAID-COL\",\n          \"DOD-DARPA-MTO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agency_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 222,\n        \"samples\": [\n          \"Health Resources and Services Administration\",\n          \"Ohio State Office\",\n          \"National Archives and Records Administration\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"mandatory\",\n          \"other\",\n          \"earmark\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_explanation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"This is a sole source opportunity to be awarded to IIE.\",\n          \"Recovery Act ARRA\",\n          \"This opportunity has been canceled.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"award_ceiling\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29798773.667071298,\n        \"min\": 0.0,\n        \"max\": 1300000000.0,\n        \"num_unique_values\": 598,\n        \"samples\": [\n          367500.0,\n          864197.0,\n          1475000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"award_floor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19889336.538489774,\n        \"min\": 0.0,\n        \"max\": 1300000000.0,\n        \"num_unique_values\": 326,\n        \"samples\": [\n          143938.0,\n          70000.0,\n          458331.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"estimated_total_funding\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72766929.25432952,\n        \"min\": 0.0,\n        \"max\": 2600000000.0,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          224766.0,\n          4725000.0,\n          3000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expected_awards\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3301.663859987734,\n        \"min\": 0.0,\n        \"max\": 175000.0,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          23.0,\n          225.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"2009-07-06\",\n          \"2008-11-11\",\n          \"2008-01-15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 724,\n        \"samples\": [\n          \"2010-05-20\",\n          \"2009-04-09\",\n          \"2009-10-30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"funding_categories\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 324,\n        \"samples\": [\n          \"income_security_and_social_services,health,environment,education\",\n          \"food_and_nutrition,health,education\",\n          \"education,food_and_nutrition,health\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"applicant_types\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1864,\n        \"samples\": [\n          \"county_governments\",\n          \"federally_recognized_native_american_tribal_governments,other,nonprofits_non_higher_education_with_501c3,nonprofits_non_higher_education_without_501c3,other_native_american_tribal_organizations,public_and_state_institutions_of_higher_education,state_governments,private_institutions_of_higher_education,for_profit_organizations_other_than_small_businesses,small_businesses\",\n          \"private_institutions_of_higher_education,state_governments,nonprofits_non_higher_education_without_501c3,public_and_state_institutions_of_higher_education,small_businesses,nonprofits_non_higher_education_with_501c3,for_profit_organizations_other_than_small_businesses\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"funding_instruments\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 48,\n        \"samples\": [\n          \"grant,other,procurement_contract,cooperative_agreement\",\n          \"procurement_contract,cooperative_agreement\",\n          \"other,grant,cooperative_agreement,procurement_contract\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4751,\n        \"samples\": [\n          \"The Office of Naval Research (ONR) is interested in receiving proposals describing innovative scientific concepts that will form the foundation for future technologies that may be developed and implemented to efficiently and effectively address future asymmetric threats, resulting in explosive events.  This BAA is part of a basic research program, and as such the knowledge and technologies developed here may lead to future applied research; however, research under this program is limited to fundamentally new theories, data, concepts, and principles.  \",\n          \"This analysis will not only provide the public with information on the salt deposits in the Paradox basin in order for possible mineral development and leasing, but it will provide the BLM a basis for management by helping to define \\u0093Known\\u0094 potash leasing areas on Federal lands.  The BLM will provide all information that is available in its files as far as drill hole analysis and location.  The BLM will also provide technical oversight on developing the basis for the analysis and will periodically review the technical approach.  BLM will then review the final analysis and provide any comments necessary to help with the project.  The UGS will use their data base in order to analysis all the information available to come up with an interpretation of the potash resources in the basin.  The UGS will provide the publicly available information to any interested parties.  Because this is an effort that the UGS also has responsibility for they are providing funding to assist with the effort.  The UGS will utilize their technical expertise in saline minerals.  The principle on the project will be Dr. Wally Gwynne who has focused his work on the saline resources in Utah particularly the Great Salt Lake, Sevier Lake and Paradox Basin.\",\n          \"The Office of Global Educational Programs of the Bureau of Educational and Cultural Affairs (ECA), U.S. Department of State, announces an open competition for three assistance awards to administer components of the Office's Teacher Exchange Program in Fiscal Year 2009. Public and private non-profit organizations or consortia of eligible organizations meeting the provisions described in Internal Revenue Code section 501(c)(3) may submit proposals to cooperate with the Bureau in the administration of the teacher exchange programs as categorized below. To facilitate effective communication between ECA's Teacher Exchange Branch (ECA/A/S/X) and the organization(s) cooperating on these programs, applicant organizations should have offices and staffs located in Washington, D.C. at the time of application. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eligibility_description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2051,\n        \"samples\": [\n          \"Applications may be submitted by Federal agencies, national laboratories, colleges and universities, research institutions and organizations, private organizations or corporations, State agricultural experiment stations, individuals, or groups consisting of 2 or more of these entities.\",\n          \"Additional eligibility types:  Local Governments   Regional Organizations   Indian/Native American Tribally Designated Organizations   Hispanic-Serving Institutions   Historically Black Colleges and Universities (HBCUs)   Tribally Controlled Colleges and Universities (TCCUs)   Alaska Native and Native Hawaiian Serving Institutions   Eligibility is limited to local public or private non-profit organizations, including faith-based organizations or local for-profit organizations in the community to be served, that can provide Early Head Start services to children and families residing in Philadelphia, Pennsylvania.  Faith-based and community organizations are eligible to apply.  Foreign entities are not eligible under this announcement.  \",\n          \"DOE is issuing this Request Information for\\ninformation and feedback from\\nstakeholders and the research community. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "grants_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV4kT5e5bjFP"
      },
      "source": [
        "# removed the data points with mising eligibility description cause this data is tangible and needs to be there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pudjgI4a0OF",
        "outputId": "35894710-dccc-4a8f-b4d5-53e50532f589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (5000, 19)\n",
            "New dataset shape: (3470, 19)\n",
            "Removed 1530 rows with missing eligibility descriptions\n",
            "\n",
            "Columns in cleaned dataset:\n",
            "- opportunity_id\n",
            "- opportunity_number\n",
            "- opportunity_title\n",
            "- opportunity_status\n",
            "- agency\n",
            "- agency_code\n",
            "- agency_name\n",
            "- category\n",
            "- award_ceiling\n",
            "- award_floor\n",
            "- estimated_total_funding\n",
            "- expected_awards\n",
            "- post_date\n",
            "- close_date\n",
            "- funding_categories\n",
            "- applicant_types\n",
            "- funding_instruments\n",
            "- summary_description\n",
            "- eligibility_description\n",
            "\n",
            "Missing values in cleaned dataset:\n",
            "opportunity_id               0\n",
            "opportunity_number           0\n",
            "opportunity_title            0\n",
            "opportunity_status           0\n",
            "agency                       0\n",
            "agency_code                  0\n",
            "agency_name                  0\n",
            "category                     1\n",
            "award_ceiling                0\n",
            "award_floor                  0\n",
            "estimated_total_funding      0\n",
            "expected_awards              0\n",
            "post_date                    0\n",
            "close_date                 332\n",
            "funding_categories           2\n",
            "applicant_types              2\n",
            "funding_instruments          2\n",
            "summary_description          0\n",
            "eligibility_description      0\n",
            "dtype: int64\n",
            "\n",
            "Monetary fields summary:\n",
            "       award_ceiling   award_floor  estimated_total_funding\n",
            "count   3.470000e+03  3.470000e+03             3.470000e+03\n",
            "mean    3.004755e+06  6.965569e+05             1.054363e+07\n",
            "std     3.353319e+07  2.267822e+07             8.594219e+07\n",
            "min     0.000000e+00  0.000000e+00             0.000000e+00\n",
            "25%     0.000000e+00  0.000000e+00             0.000000e+00\n",
            "50%     5.000000e+04  0.000000e+00             1.327375e+05\n",
            "75%     4.000000e+05  1.000000e+03             2.000000e+06\n",
            "max     1.300000e+09  1.300000e+09             2.600000e+09\n",
            "\n",
            "Sample of cleaned dataset:\n",
            "   opportunity_id      opportunity_number                                  opportunity_title  \\\n",
            "0           15936              07HQPA0028  Cooperative Ecosystem Studies Unit, Rocky Moun...   \n",
            "1           15937    ED-GRANTS-070907-001  Youth violence and related issues in persisten...   \n",
            "2           15939    ED-GRANTS-070907-002  State data collection; technical assistance CF...   \n",
            "3           15941       NNH07ZEA001N-EDL1        ROA 2007: A.6 Entry, Descent, and Landing 1   \n",
            "4           17675  CNCS-GRANTS-071307-001                               Volunteer Management   \n",
            "\n",
            "  opportunity_status     agency agency_code                                     agency_name  \\\n",
            "0           archived  DOI-USGS1   DOI-USGS1                               Geological Survey   \n",
            "1           archived         ED          ED                         Department of Education   \n",
            "2           archived         ED          ED                         Department of Education   \n",
            "3           archived    NASA-HQ     NASA-HQ                               NASA Headquarters   \n",
            "4           archived       CNCS        CNCS  Corporation for National and Community Service   \n",
            "\n",
            "        category  award_ceiling  award_floor  estimated_total_funding  expected_awards  \\\n",
            "0  discretionary        24957.0      24957.0                  24957.0              1.0   \n",
            "1  discretionary            0.0          0.0                8594000.0             13.0   \n",
            "2  discretionary       400000.0          0.0               13500000.0              0.0   \n",
            "3  discretionary            0.0          0.0                      0.0              0.0   \n",
            "4  discretionary       200000.0      50000.0                 800000.0              6.0   \n",
            "\n",
            "    post_date  close_date                                 funding_categories  \\\n",
            "0  2007-07-09  2007-07-19  science_technology_and_other_research_and_deve...   \n",
            "1  2007-07-09  2007-08-08                                          education   \n",
            "2  2007-07-09  2007-08-23                                          education   \n",
            "3  2007-07-09  2007-08-20  science_technology_and_other_research_and_deve...   \n",
            "4  2007-07-13  2007-09-06  disaster_prevention_and_relief,regional_develo...   \n",
            "\n",
            "                                     applicant_types          funding_instruments  \\\n",
            "0                                              other        cooperative_agreement   \n",
            "1                                              other                        grant   \n",
            "2                                              other                        grant   \n",
            "3                                       unrestricted  cooperative_agreement,grant   \n",
            "4  county_governments,nonprofits_non_higher_educa...                        grant   \n",
            "\n",
            "                                 summary_description  \\\n",
            "0  The U.S. Geological Surveys is offering a coo...   \n",
            "1  Note:  Each funding opportunity description i...   \n",
            "2  Note:  Each funding opportunity description i...   \n",
            "3  The National Aeronautics and Space Administrat...   \n",
            "4  The Corporation for National and Community Ser...   \n",
            "\n",
            "                             eligibility_description  \n",
            "0  This financial assistance opportunity is being...  \n",
            "1  Eligible Applicants: LEAs in which at least on...  \n",
            "2  Note: Eligible entities must submit separate a...  \n",
            "3                                       Unrestricted  \n",
            "4  The Corporation wants to ensure that all eligi...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load grants data\n",
        "grants_df = pd.read_csv('grants_clean.csv')\n",
        "\n",
        "# Remove category_explanation column\n",
        "grants_df = grants_df.drop('category_explanation', axis=1)\n",
        "\n",
        "# Remove rows with missing eligibility description\n",
        "grants_df_clean = grants_df[grants_df['eligibility_description'].notna()]\n",
        "\n",
        "# Print summary of changes\n",
        "print(\"Original dataset shape:\", grants_df.shape)\n",
        "print(\"New dataset shape:\", grants_df_clean.shape)\n",
        "print(f\"Removed {grants_df.shape[0] - grants_df_clean.shape[0]} rows with missing eligibility descriptions\")\n",
        "\n",
        "# Display data info\n",
        "print(\"\\nColumns in cleaned dataset:\")\n",
        "for col in grants_df_clean.columns:\n",
        "    print(f\"- {col}\")\n",
        "\n",
        "print(\"\\nMissing values in cleaned dataset:\")\n",
        "print(grants_df_clean.isnull().sum())\n",
        "\n",
        "# Show sample of monetary columns\n",
        "print(\"\\nMonetary fields summary:\")\n",
        "money_cols = ['award_ceiling', 'award_floor', 'estimated_total_funding']\n",
        "print(grants_df_clean[money_cols].describe())\n",
        "\n",
        "# Save cleaned dataset\n",
        "grants_df_clean.to_csv('grants_final.csv', index=False)\n",
        "\n",
        "# Show head of cleaned dataset with better formatting\n",
        "print(\"\\nSample of cleaned dataset:\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "print(grants_df_clean.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExrDy58IcuEu"
      },
      "source": [
        "# Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTMLiQmycFp6"
      },
      "outputs": [],
      "source": [
        "def clean_grants_data(grants_df):\n",
        "    # Make a copy\n",
        "    df = grants_df.copy()\n",
        "\n",
        "    # Handle missing values\n",
        "    df['close_date'] = 'unknown'  # Set all close dates to unknown for now\n",
        "    df['category'] = df['category'].fillna('unknown')  # Fill missing category\n",
        "\n",
        "    # Convert monetary values to float and handle missing values\n",
        "    numeric_cols = ['award_ceiling', 'award_floor', 'estimated_total_funding', 'expected_awards']\n",
        "    df[numeric_cols] = df[numeric_cols].fillna(0.0)\n",
        "\n",
        "    # Clean up text fields\n",
        "    text_cols = ['funding_categories', 'applicant_types', 'funding_instruments',\n",
        "                 'summary_description', 'eligibility_description']\n",
        "    df[text_cols] = df[text_cols].fillna('')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCP7K66RcrBm"
      },
      "outputs": [],
      "source": [
        "def engineer_grant_features(grants_df):\n",
        "    df = grants_df.copy()\n",
        "\n",
        "    # Create amount-related features\n",
        "    df['has_funding_limit'] = (df['award_ceiling'] > 0).astype(int)\n",
        "    df['funding_range'] = df['award_ceiling'] - df['award_floor']\n",
        "\n",
        "    # Text-based features\n",
        "    df['description_length'] = df['summary_description'].str.len()\n",
        "    df['eligibility_length'] = df['eligibility_description'].str.len()\n",
        "\n",
        "    # Categorical encoding\n",
        "    df['funding_types_count'] = df['funding_instruments'].str.count(',') + 1\n",
        "    df['applicant_types_count'] = df['applicant_types'].str.count(',') + 1\n",
        "\n",
        "    # Agency grouping\n",
        "    df['agency_group'] = df['agency_name'].map(lambda x: x.split()[0] if pd.notna(x) else 'unknown')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDH50t09csej"
      },
      "outputs": [],
      "source": [
        "def engineer_researcher_features(researchers_df):\n",
        "    df = researchers_df.copy()\n",
        "\n",
        "    # Research impact features\n",
        "    df['impact_ratio'] = df['total_citations'] / df['total_works'].clip(lower=1)\n",
        "    df['recent_impact_ratio'] = df['recent_citations'] / df['recent_works_count'].clip(lower=1)\n",
        "\n",
        "    # Collaboration metrics\n",
        "    df['collaboration_score'] = df['avg_coauthors'] * df['unique_venues']\n",
        "\n",
        "    # Research diversity\n",
        "    df['venue_per_work'] = df['unique_venues'] / df['total_works'].clip(lower=1)\n",
        "\n",
        "    # Career stage indicators\n",
        "    df['career_duration'] = df['years_active']\n",
        "    df['productivity_rate'] = df['total_works'] / df['years_active'].clip(lower=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2r_ilUAczUC"
      },
      "outputs": [],
      "source": [
        "def create_matching_features(grants_df, researchers_df):\n",
        "    # Convert summary descriptions to embeddings using the same model from the notebook\n",
        "    model = SentenceTransformer(settings.FEATURES_EMBEDDING_MODEL_ID)\n",
        "\n",
        "    grant_embeddings = model.encode(grants_df['summary_description'].tolist())\n",
        "    researcher_embeddings = model.encode(researchers_df['concept_1'].astype(str).tolist())\n",
        "\n",
        "    # Create similarity features\n",
        "    similarities = cosine_similarity(grant_embeddings, researcher_embeddings)\n",
        "\n",
        "    return similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW8g-w0Sc1rJ"
      },
      "outputs": [],
      "source": [
        "def prepare_training_data(grants_df, researchers_df, similarities):\n",
        "    training_data = []\n",
        "\n",
        "    for i, grant in grants_df.iterrows():\n",
        "        for j, researcher in researchers_df.iterrows():\n",
        "            features = {\n",
        "                'grant_id': grant['opportunity_id'],\n",
        "                'researcher_id': researcher['researcher_id'],\n",
        "                'similarity_score': similarities[i][j],\n",
        "                'amount_match': 1 if researcher['total_citations'] > grant['award_floor'] else 0,\n",
        "                'career_stage_match': 1 if researcher['years_active'] >= 5 else 0,\n",
        "                # Add more matching features\n",
        "            }\n",
        "            training_data.append(features)\n",
        "\n",
        "    return pd.DataFrame(training_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jvbMKyMd9fy"
      },
      "source": [
        "# feature engineering using hopsworks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39KQ02-jfKqB",
        "outputId": "1cdf3974-5fa2-4f7a-853a-7c118142dd78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hopsworks\n",
            "  Downloading hopsworks-4.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyhumps==1.6.1 (from hopsworks)\n",
            "  Downloading pyhumps-1.6.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2.32.3)\n",
            "Collecting furl (from hopsworks)\n",
            "  Downloading furl-2.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting boto3 (from hopsworks)\n",
            "  Downloading boto3-1.35.94-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting pandas<2.2.0 (from hopsworks)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pyjks (from hopsworks)\n",
            "  Downloading pyjks-20.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mock (from hopsworks)\n",
            "  Downloading mock-5.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting avro==1.11.3 (from hopsworks)\n",
            "  Downloading avro-1.11.3.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2.0.36)\n",
            "Collecting PyMySQL[rsa] (from hopsworks)\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from hopsworks) (5.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2024.10.0)\n",
            "Collecting retrying (from hopsworks)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting hopsworks_aiomysql==0.2.1 (from hopsworks_aiomysql[sa]==0.2.1->hopsworks)\n",
            "  Downloading hopsworks_aiomysql-0.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting opensearch-py<=2.4.2,>=1.1.0 (from hopsworks)\n",
            "  Downloading opensearch_py-2.4.2-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hopsworks) (4.67.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (1.69.0)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.25.4 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (4.25.5)\n",
            "Collecting sqlalchemy (from hopsworks)\n",
            "  Downloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2024.12.14)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->hopsworks) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->hopsworks) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->hopsworks) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hopsworks) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hopsworks) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->hopsworks) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->hopsworks) (3.1.1)\n",
            "Collecting botocore<1.36.0,>=1.35.94 (from boto3->hopsworks)\n",
            "  Downloading botocore-1.35.94-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->hopsworks)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->hopsworks)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting orderedmultidict>=1.0.1 (from furl->hopsworks)\n",
            "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting javaobj-py3 (from pyjks->hopsworks)\n",
            "  Downloading javaobj_py3-0.4.4-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyasn1>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (0.4.1)\n",
            "Collecting pycryptodomex (from pyjks->hopsworks)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting twofish (from pyjks->hopsworks)\n",
            "  Downloading twofish-0.3.0.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from PyMySQL[rsa]->hopsworks) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->PyMySQL[rsa]->hopsworks) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->PyMySQL[rsa]->hopsworks) (2.22)\n",
            "Downloading hopsworks-4.1.4-py3-none-any.whl (640 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.3/640.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hopsworks_aiomysql-0.2.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyhumps-1.6.1-py3-none-any.whl (5.0 kB)\n",
            "Downloading opensearch_py-2.4.2-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.6/258.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.94-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading furl-2.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Downloading pyjks-20.0.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading botocore-1.35.94-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading javaobj_py3-0.4.4-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: avro, twofish\n",
            "  Building wheel for avro (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro: filename=avro-1.11.3-py2.py3-none-any.whl size=123913 sha256=287391e3535841232b7c1d5a767e2581ee4ce352a4168dc275b3fe9c32508f10\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/f6/41/0e0399396af07060e64d4e32c8bd259b48b98a4a114df31294\n",
            "  Building wheel for twofish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twofish: filename=twofish-0.3.0-cp310-cp310-linux_x86_64.whl size=24197 sha256=9d30805531d37b8f9d8ed5c90ce3e1155d932848dd3e1691873ce6aa2a4cd7c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/3c/27/c390be4f3e8a299d4b2836f8daa19697eb991eacbfabe25031\n",
            "Successfully built avro twofish\n",
            "Installing collected packages: twofish, pyhumps, javaobj-py3, sqlalchemy, retrying, PyMySQL, pycryptodomex, orderedmultidict, mock, jmespath, avro, pyjks, pandas, opensearch-py, hopsworks_aiomysql, furl, botocore, s3transfer, boto3, hopsworks\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMySQL-1.1.1 avro-1.11.3 boto3-1.35.94 botocore-1.35.94 furl-2.1.3 hopsworks-4.1.4 hopsworks_aiomysql-0.2.1 javaobj-py3-0.4.4 jmespath-1.0.1 mock-5.1.0 opensearch-py-2.4.2 orderedmultidict-1.0.1 pandas-2.1.4 pycryptodomex-3.21.0 pyhumps-1.6.1 pyjks-20.0.0 retrying-1.3.4 s3transfer-0.10.4 sqlalchemy-2.0.29 twofish-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install hopsworks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDfav0yWfaH7",
        "outputId": "1cb2a3c2-6c4e-4bae-8c01-261701a2b9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install loguru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ao-uutFZKPe",
        "outputId": "3b2fb37c-e392-4008-af01-53d8c2692898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hopsworks in /usr/local/lib/python3.10/dist-packages (4.1.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pyhumps==1.6.1 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2.32.3)\n",
            "Requirement already satisfied: furl in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2.1.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (1.35.94)\n",
            "Requirement already satisfied: pyjks in /usr/local/lib/python3.10/dist-packages (from hopsworks) (20.0.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.10/dist-packages (from hopsworks) (5.1.0)\n",
            "Requirement already satisfied: avro==1.11.3 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (1.11.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2.0.29)\n",
            "Requirement already satisfied: PyMySQL[rsa] in /usr/local/lib/python3.10/dist-packages (from hopsworks) (1.1.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from hopsworks) (5.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2024.10.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from hopsworks) (1.3.4)\n",
            "Requirement already satisfied: hopsworks_aiomysql==0.2.1 in /usr/local/lib/python3.10/dist-packages (from hopsworks_aiomysql[sa]==0.2.1->hopsworks) (0.2.1)\n",
            "Requirement already satisfied: opensearch-py<=2.4.2,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (2.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hopsworks) (4.67.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (1.69.0)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.25.4 in /usr/local/lib/python3.10/dist-packages (from hopsworks) (4.25.5)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2024.12.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hopsworks) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hopsworks) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->hopsworks) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->hopsworks) (3.1.1)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.94 in /usr/local/lib/python3.10/dist-packages (from boto3->hopsworks) (1.35.94)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->hopsworks) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->hopsworks) (0.10.4)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from furl->hopsworks) (1.0.1)\n",
            "Requirement already satisfied: javaobj-py3 in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (0.4.4)\n",
            "Requirement already satisfied: pyasn1>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (0.4.1)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (3.21.0)\n",
            "Requirement already satisfied: twofish in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks) (0.3.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from PyMySQL[rsa]->hopsworks) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->PyMySQL[rsa]->hopsworks) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->PyMySQL[rsa]->hopsworks) (2.22)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-01-08 19:43:07.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_feature_store\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to Hopsworks using HOPSWORKS_API_KEY env var.\u001b[0m\n",
            "\u001b[32m2025-01-08 19:43:08.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_feature_store\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mSuccessfully retrieved the feature store.\u001b[0m\n",
            "\u001b[32m2025-01-08 19:43:08.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 49>\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mConnected to Hopsworks project: findandfund\u001b[0m\n",
            "\u001b[32m2025-01-08 19:43:08.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 49>\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mFeature store: findandfund_featurestore\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1207504\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install hopsworks pandas loguru\n",
        "\n",
        "# Import required libraries\n",
        "import hopsworks\n",
        "import pandas as pd\n",
        "from loguru import logger\n",
        "\n",
        "# Define settings (replace with your actual settings)\n",
        "class Settings:\n",
        "    def __init__(self):\n",
        "        self.HOPSWORKS_API_KEY = None  # Replace with your Hopsworks API key\n",
        "\n",
        "    def get_secret_value(self):\n",
        "        return self.HOPSWORKS_API_KEY\n",
        "\n",
        "# Initialize settings\n",
        "settings = Settings()\n",
        "\n",
        "# Define constants (replace with your actual constants)\n",
        "class Constants:\n",
        "    FEATURE_STORE_NAME = \"findandfund_feature_store\"\n",
        "\n",
        "constants = Constants()\n",
        "\n",
        "def get_feature_store():\n",
        "    \"\"\"Connect to Hopsworks and return the project and feature store.\"\"\"\n",
        "    if settings.HOPSWORKS_API_KEY:\n",
        "        logger.info(\"Logging to Hopsworks using HOPSWORKS_API_KEY env var.\")\n",
        "        project = hopsworks.login(\n",
        "            api_key_value=settings.HOPSWORKS_API_KEY,  # No .get_secret_value() needed\n",
        "            host='c.app.hopsworks.ai',  # Use the host from your URL\n",
        "            project=\"findandfund\"\n",
        "        )\n",
        "    else:\n",
        "        logger.info(\"Login to Hopsworks using cached API key.\")\n",
        "        project = hopsworks.login(\n",
        "            host='c.app.hopsworks.ai',  # Use the host from your URL\n",
        "            project=\"findandfund\"\n",
        "        )\n",
        "\n",
        "    # Get the feature store\n",
        "    fs = project.get_feature_store()\n",
        "    logger.info(\"Successfully retrieved the feature store.\")\n",
        "\n",
        "    return project, fs\n",
        "\n",
        "# Example usage\n",
        "try:\n",
        "    # Set your Hopsworks API key (replace with your actual key)\n",
        "    settings.HOPSWORKS_API_KEY = \"E9uA06PYlE5ktSqe.Ty7r4OBfHnG6tiiuYl8BSMRi9Ap8eeCpwhYwUYGzFv8NOrtSm4vFgs38fvO0FPgn\"\n",
        "\n",
        "    # Connect to Hopsworks\n",
        "    project, fs = get_feature_store()\n",
        "    logger.info(f\"Connected to Hopsworks project: {project.name}\")\n",
        "    logger.info(f\"Feature store: {fs.name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to connect to Hopsworks: {str(e)}\")\n",
        "    logger.warning(\"Proceeding with local file storage only.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWYQrmfNRUNJ"
      },
      "outputs": [],
      "source": [
        "def verify_hopsworks_connection():\n",
        "    \"\"\"Verify connection to Hopsworks and create/connect to the 'findandfund' project\"\"\"\n",
        "    if not HOPSWORKS_API_KEY:\n",
        "        logger.warning(\"Hopsworks API key not found. Proceeding with local file storage only.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Log the attempt to connect\n",
        "        logger.info(\"Attempting to connect to Hopsworks...\")\n",
        "\n",
        "        # Connect to Hopsworks\n",
        "        connection = hopsworks.connection(\n",
        "            host='your_hopsworks_host',  # Replace with your Hopsworks host (e.g., [UUID].cloud.hopsworks.ai)\n",
        "            port=443,\n",
        "            project=\"findandfund\",\n",
        "            api_key_value=HOPSWORKS_API_KEY,\n",
        "            hostname_verification=True\n",
        "        )\n",
        "        logger.info(\"Connected to Hopsworks successfully!\")\n",
        "\n",
        "        # Get the feature store\n",
        "        fs = connection.get_feature_store()\n",
        "        logger.info(\"Successfully retrieved the feature store.\")\n",
        "\n",
        "        return fs\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to connect to Hopsworks: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBHjzOFPeAD0",
        "outputId": "284cf91d-547d-4fd5-de20-f83f6338377f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: hopsworks[python] in /usr/local/lib/python3.10/dist-packages (4.1.4)\n",
            "Requirement already satisfied: pyhumps==1.6.1 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (2.32.3)\n",
            "Requirement already satisfied: furl in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (2.1.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (1.35.94)\n",
            "Requirement already satisfied: pyjks in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (20.0.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (5.1.0)\n",
            "Requirement already satisfied: avro==1.11.3 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (1.11.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (2.0.29)\n",
            "Requirement already satisfied: PyMySQL[rsa] in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (1.1.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (5.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (2024.10.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (1.3.4)\n",
            "Requirement already satisfied: hopsworks_aiomysql==0.2.1 in /usr/local/lib/python3.10/dist-packages (from hopsworks_aiomysql[sa]==0.2.1->hopsworks[python]) (0.2.1)\n",
            "Requirement already satisfied: opensearch-py<=2.4.2,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (2.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (1.69.0)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.25.4 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=10.0 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (17.0.0)\n",
            "Requirement already satisfied: confluent-kafka<=2.3.0 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (2.3.0)\n",
            "Requirement already satisfied: fastavro<=1.8.4,>=1.4.11 in /usr/local/lib/python3.10/dist-packages (from hopsworks[python]) (1.8.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks[python]) (2.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks[python]) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.10/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks[python]) (2024.12.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hopsworks[python]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hopsworks[python]) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->hopsworks[python]) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.94 in /usr/local/lib/python3.10/dist-packages (from boto3->hopsworks[python]) (1.35.94)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->hopsworks[python]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->hopsworks[python]) (0.10.4)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from furl->hopsworks[python]) (1.0.1)\n",
            "Requirement already satisfied: javaobj-py3 in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks[python]) (0.4.4)\n",
            "Requirement already satisfied: pyasn1>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks[python]) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks[python]) (0.4.1)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks[python]) (3.21.0)\n",
            "Requirement already satisfied: twofish in /usr/local/lib/python3.10/dist-packages (from pyjks->hopsworks[python]) (0.3.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from PyMySQL[rsa]->hopsworks[python]) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->PyMySQL[rsa]->hopsworks[python]) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->PyMySQL[rsa]->hopsworks[python]) (2.22)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries with Hopsworks Python extras\n",
        "!pip install hopsworks[python] pandas numpy sentence-transformers scikit-learn loguru tqdm\n",
        "\n",
        "# Restart the runtime to apply the changes\n",
        "import os\n",
        "os.kill(os.getpid(), 9)  # This will restart the Colab runtime\n",
        "\n",
        "# After the runtime restarts, re-run the following code:\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import hopsworks\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from loguru import logger\n",
        "from google.colab import drive, userdata\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create directory for our data\n",
        "SAVE_PATH = '/content/drive/My Drive/research_grants_data'\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Get Hopsworks API key securely\n",
        "try:\n",
        "    HOPSWORKS_API_KEY = userdata.get('HOPSWORKS_API_KEY')\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Failed to retrieve Hopsworks API key: {str(e)}\")\n",
        "    HOPSWORKS_API_KEY = None\n",
        "\n",
        "def get_feature_store():\n",
        "    \"\"\"Connect to Hopsworks and return the project and feature store.\"\"\"\n",
        "    if HOPSWORKS_API_KEY:\n",
        "        logger.info(\"Logging to Hopsworks using HOPSWORKS_API_KEY env var.\")\n",
        "        project = hopsworks.login(\n",
        "            api_key_value=HOPSWORKS_API_KEY,  # No .get_secret_value() needed\n",
        "            host='c.app.hopsworks.ai',  # Use the host from your URL\n",
        "            project=\"findandfund\"\n",
        "        )\n",
        "    else:\n",
        "        logger.info(\"Login to Hopsworks using cached API key.\")\n",
        "        project = hopsworks.login(\n",
        "            host='c.app.hopsworks.ai',  # Use the host from your URL\n",
        "            project=\"findandfund\"\n",
        "        )\n",
        "\n",
        "    # Get the feature store\n",
        "    fs = project.get_feature_store()\n",
        "    logger.info(\"Successfully retrieved the feature store.\")\n",
        "\n",
        "    return project, fs\n",
        "\n",
        "def clean_and_engineer_grants(grants_df):\n",
        "    \"\"\"Clean and engineer features for grants data\"\"\"\n",
        "    df = grants_df.copy()\n",
        "\n",
        "    # Basic cleaning\n",
        "    df['close_date'] = 'unknown'\n",
        "    df['category'] = df['category'].fillna('unknown')\n",
        "\n",
        "    # Convert monetary values and handle missing\n",
        "    numeric_cols = ['award_ceiling', 'award_floor', 'estimated_total_funding', 'expected_awards']\n",
        "    df[numeric_cols] = df[numeric_cols].fillna(0.0)\n",
        "\n",
        "    # Convert post_date to datetime (TIMESTAMP)\n",
        "    df['post_date'] = pd.to_datetime(df['post_date'], errors='coerce')  # Coerce invalid dates to NaT\n",
        "\n",
        "    # Feature Engineering\n",
        "    df['has_funding_limit'] = (df['award_ceiling'] > 0).astype(int)\n",
        "    df['funding_range'] = df['award_ceiling'] - df['award_floor']\n",
        "    df['description_length'] = df['summary_description'].str.len()\n",
        "    df['eligibility_length'] = df['eligibility_description'].str.len()\n",
        "    df['funding_types_count'] = df['funding_instruments'].str.count(',') + 1\n",
        "    df['applicant_types_count'] = df['applicant_types'].str.count(',') + 1\n",
        "    df['agency_group'] = df['agency_name'].map(lambda x: x.split()[0] if pd.notna(x) else 'unknown')\n",
        "\n",
        "    # Save processed grants\n",
        "    df.to_csv(f'{SAVE_PATH}/processed_grants.csv', index=False)\n",
        "\n",
        "    return df\n",
        "\n",
        "def engineer_researcher_features(researchers_df):\n",
        "    \"\"\"Engineer features for researcher data\"\"\"\n",
        "    df = researchers_df.copy()\n",
        "\n",
        "    # Research impact features\n",
        "    df['impact_ratio'] = df['total_citations'] / df['total_works'].clip(lower=1)\n",
        "    df['recent_impact_ratio'] = df['recent_citations'] / df['recent_works_count'].clip(lower=1)\n",
        "    df['collaboration_score'] = df['avg_coauthors'] * df['unique_venues']\n",
        "    df['venue_per_work'] = df['unique_venues'] / df['total_works'].clip(lower=1)\n",
        "    df['productivity_rate'] = df['total_works'] / df['years_active'].clip(lower=1)\n",
        "\n",
        "    # Save processed researchers\n",
        "    df.to_csv(f'{SAVE_PATH}/processed_researchers.csv', index=False)\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_embedding_features(grants_df, researchers_df, model_name='all-MiniLM-L6-v2'):\n",
        "    \"\"\"Create embeddings and compute similarities\"\"\"\n",
        "    # Load model\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    # Create embeddings\n",
        "    logger.info(\"Creating grant embeddings...\")\n",
        "    grant_descriptions = grants_df['summary_description'].fillna('').tolist()\n",
        "    grant_embeddings = model.encode(grant_descriptions, show_progress_bar=True)\n",
        "\n",
        "    logger.info(\"Creating researcher embeddings...\")\n",
        "    researcher_descriptions = researchers_df.apply(\n",
        "        lambda x: f\"{x['concept_1']} {x['concept_2']}\", axis=1\n",
        "    ).tolist()\n",
        "    researcher_embeddings = model.encode(researcher_descriptions, show_progress_bar=True)\n",
        "\n",
        "    # Save embeddings\n",
        "    np.save(f'{SAVE_PATH}/grant_embeddings.npy', grant_embeddings)\n",
        "    np.save(f'{SAVE_PATH}/researcher_embeddings.npy', researcher_embeddings)\n",
        "\n",
        "    # Compute similarities\n",
        "    logger.info(\"Computing similarities...\")\n",
        "    similarities = cosine_similarity(grant_embeddings, researcher_embeddings)\n",
        "    np.save(f'{SAVE_PATH}/similarities.npy', similarities)\n",
        "\n",
        "    return similarities\n",
        "\n",
        "def create_matching_features(grants_df, researchers_df):\n",
        "    \"\"\"Create features for grant-researcher matching\"\"\"\n",
        "    # Load saved similarities\n",
        "    similarities = np.load(f'{SAVE_PATH}/similarities.npy')\n",
        "\n",
        "    matches = []\n",
        "\n",
        "    logger.info(f\"Creating matches for {len(grants_df)} grants and {len(researchers_df)} researchers...\")\n",
        "    for i, grant in tqdm(grants_df.iterrows(), total=len(grants_df)):\n",
        "        for j, researcher in researchers_df.iterrows():\n",
        "            match_features = {\n",
        "                'grant_id': grant['opportunity_id'],\n",
        "                'researcher_id': researcher['researcher_id'],\n",
        "                'similarity_score': similarities[i][j],\n",
        "\n",
        "                # Grant features\n",
        "                'grant_award_ceiling': grant['award_ceiling'],\n",
        "                'grant_funding_range': grant['funding_range'],\n",
        "                'grant_types_count': grant['funding_types_count'],\n",
        "\n",
        "                # Researcher features\n",
        "                'researcher_impact': researcher['impact_ratio'],\n",
        "                'researcher_recent_impact': researcher['recent_impact_ratio'],\n",
        "                'researcher_collaboration': researcher['collaboration_score'],\n",
        "                'researcher_productivity': researcher['productivity_rate'],\n",
        "\n",
        "                # Matching features\n",
        "                'field_match': 1 if researcher['concept_1'] in str(grant['summary_description']) else 0,\n",
        "                'career_stage_match': 1 if researcher['years_active'] >= 5 else 0\n",
        "            }\n",
        "            matches.append(match_features)\n",
        "\n",
        "    matching_df = pd.DataFrame(matches)\n",
        "    return matching_df\n",
        "\n",
        "def create_hopsworks_feature_groups(grants_df, researchers_df, matching_features):\n",
        "    \"\"\"Create and upload feature groups to Hopsworks within the 'findandfund' project\"\"\"\n",
        "    try:\n",
        "        # Connect to Hopsworks\n",
        "        project, fs = get_feature_store()\n",
        "        if fs is None:\n",
        "            raise Exception(\"Failed to connect to Hopsworks\")\n",
        "\n",
        "        # Create grants feature group\n",
        "        logger.info(\"Creating grants feature group...\")\n",
        "        grants_fg = fs.get_or_create_feature_group(\n",
        "            name='grants',\n",
        "            version=1,\n",
        "            primary_key=['opportunity_id'],\n",
        "            description='Processed grants features',\n",
        "            online_enabled=True,\n",
        "            event_time='post_date'  # Ensure this is a valid TIMESTAMP column\n",
        "        )\n",
        "        grants_fg.insert(grants_df, write_options={\"wait_for_job\": True})\n",
        "\n",
        "        # Create researchers feature group\n",
        "        logger.info(\"Creating researchers feature group...\")\n",
        "        researchers_fg = fs.get_or_create_feature_group(\n",
        "            name='researchers',\n",
        "            version=1,\n",
        "            primary_key=['researcher_id'],\n",
        "            description='Processed researcher features',\n",
        "            online_enabled=True\n",
        "        )\n",
        "        researchers_fg.insert(researchers_df, write_options={\"wait_for_job\": True})\n",
        "\n",
        "        # Create matching feature group\n",
        "        logger.info(\"Creating matching feature group...\")\n",
        "        matching_fg = fs.get_or_create_feature_group(\n",
        "            name='grant_researcher_matching',\n",
        "            version=1,\n",
        "            primary_key=['grant_id', 'researcher_id'],\n",
        "            description='Grant-researcher matching features',\n",
        "            online_enabled=True\n",
        "        )\n",
        "        matching_fg.insert(matching_features, write_options={\"wait_for_job\": True})\n",
        "\n",
        "        return grants_fg, researchers_fg, matching_fg\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating feature groups: {str(e)}\")\n",
        "        # Save the data locally if Hopsworks upload fails\n",
        "        grants_df.to_csv(f'{SAVE_PATH}/grants_features.csv', index=False)\n",
        "        researchers_df.to_csv(f'{SAVE_PATH}/researchers_features.csv', index=False)\n",
        "        matching_features.to_csv(f'{SAVE_PATH}/matching_features.csv', index=False)\n",
        "        logger.info(f\"Data saved locally to {SAVE_PATH}\")\n",
        "        return None, None, None\n",
        "\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize variables to avoid UnboundLocalError\n",
        "    grants_processed = None\n",
        "    researchers_processed = None\n",
        "    matching_features = None\n",
        "\n",
        "    try:\n",
        "        # Load your existing dataframes from the Colab environment\n",
        "        logger.info(\"Loading data...\")\n",
        "        grants_df = pd.read_csv('grants_clean.csv')\n",
        "        researchers_df = pd.read_csv('researchers_clean.csv')\n",
        "\n",
        "        # Process data\n",
        "        logger.info(\"Processing grants data...\")\n",
        "        grants_processed = clean_and_engineer_grants(grants_df)\n",
        "\n",
        "        logger.info(\"Processing researcher data...\")\n",
        "        researchers_processed = engineer_researcher_features(researchers_df)\n",
        "\n",
        "        # Create embeddings and similarities\n",
        "        logger.info(\"Creating embeddings and computing similarities...\")\n",
        "        create_embedding_features(grants_processed, researchers_processed)\n",
        "\n",
        "        # Create matching features\n",
        "        logger.info(\"Creating matching features...\")\n",
        "        matching_features = create_matching_features(grants_processed, researchers_processed)\n",
        "        matching_features.to_csv(f'{SAVE_PATH}/matching_features.csv', index=False)\n",
        "\n",
        "        # Create Hopsworks feature groups with error handling\n",
        "        logger.info(\"Creating Hopsworks feature groups...\")\n",
        "        grants_fg, researchers_fg, matching_fg = create_hopsworks_feature_groups(\n",
        "            grants_processed, researchers_processed, matching_features\n",
        "        )\n",
        "\n",
        "        if all([grants_fg, researchers_fg, matching_fg]):\n",
        "            # Create training/validation split\n",
        "            logger.info(\"Creating train/validation split...\")\n",
        "            train_df = matching_features.sample(frac=0.8, random_state=42)\n",
        "            val_df = matching_features.drop(train_df.index)\n",
        "\n",
        "            # Save splits\n",
        "            train_df.to_csv(f'{SAVE_PATH}/train_data.csv', index=False)\n",
        "            val_df.to_csv(f'{SAVE_PATH}/val_data.csv', index=False)\n",
        "\n",
        "        execution_time = time.time() - start_time\n",
        "        logger.info(f\"Total execution time: {execution_time/60:.2f} minutes\")\n",
        "        logger.info(f\"All files saved to: {SAVE_PATH}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        logger.warning(\"Process interrupted by user. Saving intermediate results...\")\n",
        "        # Save any intermediate results that were generated\n",
        "        for df_name, df in [\n",
        "            ('grants_processed.csv', grants_processed),\n",
        "            ('researchers_processed.csv', researchers_processed),\n",
        "            ('matching_features.csv', matching_features)\n",
        "        ]:\n",
        "            if df is not None:\n",
        "                df.to_csv(f'{SAVE_PATH}/{df_name}', index=False)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main execution: {str(e)}\")\n",
        "        logger.info(\"Saving intermediate results...\")\n",
        "        # Save any intermediate results that were generated\n",
        "        for df_name, df in [\n",
        "            ('grants_processed.csv', grants_processed),\n",
        "            ('researchers_processed.csv', researchers_processed),\n",
        "            ('matching_features.csv', matching_features)\n",
        "        ]:\n",
        "            if df is not None:\n",
        "                df.to_csv(f'{SAVE_PATH}/{df_name}', index=False)\n",
        "\n",
        "# Verify Hopsworks connection before running main\n",
        "project, fs = get_feature_store()\n",
        "if fs is None:\n",
        "    logger.warning(\"Proceeding with local file storage only\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP-797EHeRPn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7WyTE2cBid/rMCFTsPUTD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}